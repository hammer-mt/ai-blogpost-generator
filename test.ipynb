{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat the blog outline and transcript as fixed inputs.\n",
    "\n",
    "topic = \"Using Pocketbase as a backend for a FastAPI HTMX app\"\n",
    "\n",
    "filename = \"transcript.txt\"\n",
    "\n",
    "with open(filename, \"r\") as file:\n",
    "    transcript = file.read()\n",
    "\n",
    "blog_outline = {\n",
    "  \"hook\": \"Explore the seamless integration of Pocketbase with FastAPI and HTMX, and discover how to overcome common challenges in building a robust backend for your web applications.\",\n",
    "  \"section1\": \"Discuss the straightforward setup of using Pocketbase with FastAPI and HTMX, and address the potential challenges of integrating Alpine.js, offering solutions to ensure a smooth development process.\",\n",
    "  \"section2\": \"Examine Pocketbase's authentication system, highlighting its simplicity and reusability, while addressing the potential confusion around client-side password hashing and suggesting best practices for secure authentication.\",\n",
    "  \"section3\": \"Analyze the pros and cons of using server-based cookies for authentication, comparing them with alternative methods like JSON Web Tokens (JWTs) and cryptographic keys, to help developers choose the best solution for their specific use cases.\",\n",
    "  \"section4\": \"Explore the manual setup process for creating collections in Pocketbase, and provide insights on how to automate this process with admin access to enhance efficiency.\",\n",
    "  \"section5\": \"Highlight the benefits of deploying FastAPI and Pocketbase on Railway, emphasizing its simplicity and cost-effectiveness for small to medium projects, and provide a brief guide on getting started.\",\n",
    "  \"section6\": \"Address the productivity bottleneck caused by the lack of boilerplate, and discuss how building a custom boilerplate can streamline project deployment and iteration, ultimately boosting productivity.\",\n",
    "  \"section7\": \"Compare Pocketbase's logging capabilities with other platforms like Google Cloud, focusing on how its superior logging features can simplify debugging and improve performance.\",\n",
    "  \"section8\": \"Offer strategies for solo developers to simplify their tech stack and deployment process, thereby speeding up project iteration and reducing overhead, with practical tips for implementation.\",\n",
    "  \"conclusion\": \"Summarize the key insights on using Pocketbase as a backend for a FastAPI HTMX app, reinforcing the importance of choosing the right tools and strategies to optimize development efficiency and security.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant chunks for query: FastAPI and Pocketbase setup\n",
      "\n",
      "Chunk 1:\n",
      "########################\n",
      "215\n",
      "21:35.056 --> 21:41.408\n",
      "<v Michael Taylor>And that's also like a pretty nice stack because you've got your own database there and you're not dependent on\n",
      "\n",
      "\n",
      "216\n",
      "21:41.472 --> 21:42.176\n",
      "<v Michael Taylor>other things.\n",
      "\n",
      "\n",
      "217\n",
      "21:42.296 --> 21:50.176\n",
      "<v Michael Taylor>But I wanted to explore pocket base just because it's more like that super based type experience but actually even\n",
      "\n",
      "\n",
      "218\n",
      "21:50.216 --> 21:53.996\n",
      "<v Michael Taylor>simpler it looks like. So I think this is way easier.\n",
      "\n",
      "\n",
      "219\n",
      "21:55.056 --> 22:01.708\n",
      "<v Michael Taylor>And then the benefit is, is then you don't like because the database is separate from the fast API application.\n",
      "\n",
      "\n",
      "220\n",
      "22:01.772 --> 22:11.204\n",
      "<v Michael Taylor>Now you can deploy a fast API separately like this because previously I hadn't tried railway yet and I was\n",
      "\n",
      "\n",
      "221\n",
      "22:11.220 --> 22:17.016\n",
      "<v Michael Taylor>using Google Cloud run to get fast API stuff deployed.\n",
      "########################\n",
      "\n",
      "\n",
      "Chunk 2:\n",
      "########################\n",
      "195\n",
      "19:28.356 --> 19:36.892\n",
      "<v Ellis Crosby>Okay, cool. Yeah, it's mostly just the, like, the app itself doesn't cost that much. It's just the database. So.\n",
      "\n",
      "\n",
      "196\n",
      "19:36.964 --> 19:41.256\n",
      "<v Ellis Crosby>Yeah. You can also probably plug that into a database somewhere else.\n",
      "\n",
      "\n",
      "197\n",
      "19:42.836 --> 19:50.736\n",
      "<v Michael Taylor>Yeah. And then you're also launching your fast API app on a railway as well.\n",
      "\n",
      "\n",
      "198\n",
      "19:51.156 --> 20:04.216\n",
      "<v Ellis Crosby>Yeah, exactly. And again, that's a pretty, pretty easy thing. Like you need to drop a piece of profile.\n",
      "\n",
      "\n",
      "199\n",
      "20:10.356 --> 20:17.661\n",
      "<v Ellis Crosby>It's like. Yeah, just like one file you put in just so it deploys. But yeah, it's a pretty easy.\n",
      "\n",
      "\n",
      "200\n",
      "20:17.773 --> 20:20.705\n",
      "<v Michael Taylor>Oh, literally just that. So that just tells it what to run.\n",
      "\n",
      "\n",
      "201\n",
      "20:21.725 --> 20:23.305\n",
      "<v Ellis Crosby>Yeah, yeah, exactly.\n",
      "########################\n",
      "\n",
      "\n",
      "Chunk 3:\n",
      "########################\n",
      "102\n",
      "09:43.739 --> 09:46.275\n",
      "<v Michael Taylor>create it in pocket space first or.\n",
      "\n",
      "\n",
      "103\n",
      "09:46.459 --> 09:51.707\n",
      "<v Michael Taylor>That was the other bug I ran into just before this call was like, I tried to send something off,\n",
      "\n",
      "\n",
      "104\n",
      "09:51.755 --> 09:54.219\n",
      "<v Michael Taylor>like add it. For me, it was like a testimonials app.\n",
      "\n",
      "\n",
      "105\n",
      "09:54.251 --> 09:59.391\n",
      "<v Michael Taylor>So I add a testimonial, but it ended up like it rejected it.\n",
      "\n",
      "\n",
      "106\n",
      "09:59.407 --> 10:01.563\n",
      "<v Michael Taylor>So I haven't had a chance to look into it yet.\n",
      "\n",
      "\n",
      "107\n",
      "10:02.343 --> 10:09.807\n",
      "<v Ellis Crosby>Yeah, so it's, yeah, so I'm not sure if you use superbase too much, but it's a similar kind of\n",
      "\n",
      "\n",
      "108\n",
      "10:09.815 --> 10:15.443\n",
      "<v Ellis Crosby>setup where you have to add rules to the tables as to who can do what.\n",
      "\n",
      "\n",
      "109\n",
      "10:15.943 --> 10:21.043\n",
      "<v Ellis Crosby>So if I jump into the interface for that one.\n",
      "########################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# recreate the embeddings functions from poc.ipynb\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Assuming 'transcript' variable contains the full transcript text\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_text(transcript)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_texts(chunks, embeddings)\n",
    "\n",
    "# Function to retrieve relevant chunks for each section\n",
    "def get_relevant_chunks(query, k=3):\n",
    "    return vectorstore.similarity_search(query, k=k)\n",
    "\n",
    "# Test the get_relevant_chunks function\n",
    "test_query = \"FastAPI and Pocketbase setup\"\n",
    "relevant_chunks = get_relevant_chunks(test_query)\n",
    "\n",
    "print(\"Relevant chunks for query:\", test_query)\n",
    "for i, chunk in enumerate(relevant_chunks, 1):\n",
    "    print(f\"\\nChunk {i}:\")\n",
    "    print(\"########################\")\n",
    "    print(chunk.page_content)\n",
    "    print(\"########################\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating content for section: hook\n",
      "Generating content for section: section1\n",
      "Generating content for section: section2\n",
      "Generating content for section: section3\n",
      "Generating content for section: section4\n",
      "Generating content for section: section5\n",
      "Generating content for section: section6\n",
      "Generating content for section: section7\n",
      "Generating content for section: section8\n",
      "Generating content for section: conclusion\n",
      "\n",
      "\n",
      "##################################################\n",
      "Section: hook\n",
      "##################################################\n",
      "\n",
      "Pocketbase, FastAPI, and HTMX together make a killer combo for building web apps. It's like having your own database without the hassle of relying on other services. Pocketbase is super simple, almost like a stripped-down version of Supabase, but even easier. The beauty of this setup is that your database is separate from your FastAPI app, so you can deploy them independently. This separation means you can tweak and scale your backend without messing with your database, which is a huge win for flexibility.\n",
      "\n",
      "Now, let's talk about the challenges. Integrating these tools isn't always a walk in the park. You might hit some bumps with Alpine.js if you're using it alongside HTMX. The key is to keep your components organized and let each tool do what it does best. FastAPI handles the backend logic, HTMX takes care of the dynamic front-end interactions, and Pocketbase manages your data. Once you get the hang of it, this stack is a breeze to work with, and you'll wonder how you ever managed without it.\n",
      "\n",
      "\n",
      "##################################################\n",
      "Section: section1\n",
      "##################################################\n",
      "\n",
      "Setting up Pocketbase with FastAPI and HTMX is like assembling a Lego set—everything just clicks into place. FastAPI is your backend powerhouse, while HTMX handles the front-end interactions without the need for heavy JavaScript frameworks. You get a clean, efficient setup that lets you focus on building features rather than wrestling with infrastructure. The beauty of this stack is its simplicity; Pocketbase acts as your database, and you can deploy FastAPI separately, making it a breeze to manage and scale. It's like having your own little ecosystem where each component knows its role and plays it well.\n",
      "\n",
      "Now, let's talk about Alpine.js. Integrating it can be a bit of a head-scratcher, especially when you're juggling it with HTMX. The key is to let each tool do what it does best. Use HTMX for server-driven interactions and Alpine.js for client-side interactivity. They can coexist peacefully if you keep their responsibilities clear. If you hit a snag, check your event listeners and data bindings—those are usually the culprits. And remember, it's all about balance. Don't overcomplicate things; keep your code clean and your mind clearer. You'll thank yourself later.\n",
      "\n",
      "\n",
      "##################################################\n",
      "Section: section2\n",
      "##################################################\n",
      "\n",
      "Alright, let's dive into Pocketbase's authentication system. It's like, super straightforward, which is awesome if you're tired of jumping through hoops just to get users logged in. The beauty of it is in its simplicity and reusability. You set it up once, and you're good to go for multiple projects. But here's the kicker: client-side password hashing can be a bit of a head-scratcher. You might be like, 'Wait, why aren't we hashing passwords on the client side?' Turns out, Pocketbase handles it on the server side, which is actually a good thing for security. Keeps things tight and less prone to client-side shenanigans.\n",
      "\n",
      "Now, about best practices for secure authentication—keep it simple, but don't skimp on security. Always use HTTPS to protect data in transit. And while Pocketbase does the heavy lifting with password hashing, make sure you're using strong, unique passwords and consider implementing two-factor authentication for an extra layer of security. It's like adding a deadbolt to your front door. Also, keep your Pocketbase instance updated to patch any vulnerabilities. It's all about finding that sweet spot between ease of use and keeping the bad guys out. So, yeah, Pocketbase makes it easy, but don't get lazy with security. Cool?\n",
      "\n",
      "\n",
      "##################################################\n",
      "Section: section3\n",
      "##################################################\n",
      "\n",
      "Alright, let's dive into the cookie vs JWT vs cryptographic keys debate. Server-based cookies are like the old reliable of authentication. They're simple, and they work. You set a cookie on the server, and it gets sent with every request. Easy peasy. But, they can be a bit of a pain with scaling. You gotta keep track of sessions, which can get messy if you're running multiple servers. Plus, cookies can be vulnerable to CSRF attacks if you're not careful. On the flip side, they're great for keeping things secure on the server side, and you don't have to worry about token expiration as much.\n",
      "\n",
      "Now, JWTs are the cool kids on the block. They're stateless, which means no session storage on the server. This makes them super scalable. You can just chuck a token at the client, and they can use it until it expires. But, with great power comes great responsibility. If a JWT gets compromised, it's game over until it expires. Also, they're a bit heavier on the payload side, which can be a drag on performance. Cryptographic keys, on the other hand, are like the secret agents of authentication. They're super secure but can be complex to implement. You gotta manage key distribution and rotation, which can be a headache. So, it really boils down to your specific needs. Want simplicity? Go cookies. Need scalability? JWTs. Security your top priority? Cryptographic keys might be your jam.\n",
      "\n",
      "\n",
      "##################################################\n",
      "Section: section4\n",
      "##################################################\n",
      "\n",
      "Setting up collections in Pocketbase manually is like assembling IKEA furniture without instructions. You dive into the admin interface, click around, and hope you don't end up with extra screws. It's straightforward but can be a bit tedious if you're doing it repeatedly. You create a collection, define fields, and set rules. It's all GUI-based, which is nice for visual folks, but if you're a command-line junkie, it might feel like a slow dance. The real kicker is when you need to migrate or replicate this setup across environments. That's when you start wishing for a magic wand.\n",
      "\n",
      "Now, if you're lucky enough to have admin access, you can automate this process and save yourself from the repetitive click-fest. With admin rights, you can script the creation of collections via the API. This means you can define your collections in code, check if they exist, and create them if they don't. It's like having a robot do your IKEA assembly. You can even import collections from a JSON file, which is a lifesaver if you're switching Pocketbase instances or need to set up a new environment quickly. It's not perfect, and you'll probably hit a few bumps with error messages, but it's a hell of a lot better than doing it all by hand.\n",
      "\n",
      "\n",
      "##################################################\n",
      "Section: section5\n",
      "##################################################\n",
      "\n",
      "Deploying FastAPI and Pocketbase on Railway is like having your cake and eating it too, but without the cake. It's simple and cost-effective, especially for small to medium projects. You get to keep your database separate from your FastAPI app, which is pretty sweet. No more dependency headaches. Plus, Railway's pay-as-you-go model means you're only shelling out for what you actually use. So, if you're not running a massive database, it's pretty cheap. Like, $13 a month for a big database with 500 log articles and images? That's a steal.\n",
      "\n",
      "Getting started is a breeze. First, you need to create your admin account in the Railway interface. Then, just drop a profile file in your project to tell Railway what to run. It's literally just that. For FastAPI, make sure you've got the right port and variable set up, and you're good to go. Railway charges based on usage, so if you need more workers, you'll pay a bit more, but it's usually fair. It's like having a super simple setup without the usual cloud deployment drama. So, go ahead, give it a shot. You might just love it.\n",
      "\n",
      "\n",
      "##################################################\n",
      "Section: section6\n",
      "##################################################\n",
      "\n",
      "Alright, let's talk about the productivity bottleneck when there's no boilerplate. It's like trying to build a house without a blueprint. You end up spending way too much time on repetitive tasks instead of focusing on the cool stuff that actually matters. Without a boilerplate, every project feels like reinventing the wheel, and honestly, who has time for that? Building a custom boilerplate can be a game-changer. It streamlines project deployment and iteration, making everything smoother and faster. You get to skip the boring setup and dive straight into the fun parts of development. Plus, it gives you a solid foundation to build on, so you can focus on innovation rather than setup.\n",
      "\n",
      "Creating a custom boilerplate isn't just about saving time; it's about boosting productivity. When you have a reliable starting point, you can iterate quickly and deploy with confidence. It's like having a secret weapon in your dev toolkit. You can tackle projects with a clear roadmap, reducing the chances of getting bogged down by mundane tasks. And let's be real, it also gives you fewer excuses to procrastinate. With a boilerplate, you can yolo your way into main and get things live without the usual headaches. So, if you're serious about upping your productivity game, investing time in building a custom boilerplate is a no-brainer.\n",
      "\n",
      "\n",
      "##################################################\n",
      "Section: section7\n",
      "##################################################\n",
      "\n",
      "Pocketbase's logging is like a breath of fresh air compared to Google Cloud. Seriously, it's like night and day. With Pocketbase, you get logs that actually tell you what's going on. No more cryptic messages that leave you scratching your head. It's straightforward and gives you the info you need to fix issues fast. Debugging becomes less of a nightmare and more of a 'let's get this done' kind of task. It's like having a friend who actually listens and gives you good advice, instead of just nodding along.\n",
      "\n",
      "When you're dealing with performance issues, Pocketbase's logs are a lifesaver. They help you pinpoint exactly where things are going wrong, so you can optimize your app without the guesswork. Google Cloud's logs? Not so much. They're like trying to read a novel in a language you barely understand. With Pocketbase, you get clarity and efficiency, which means you spend less time digging through logs and more time making your app awesome. It's all about making your life easier, and Pocketbase nails it.\n",
      "\n",
      "\n",
      "##################################################\n",
      "Section: section8\n",
      "##################################################\n",
      "\n",
      "Alright, solo devs, let's cut the crap and get straight to it. Simplifying your tech stack is like cleaning out your closet—ditch the stuff you don't need. First, pick tools that play nice together. FastAPI and Pocketbase are a dream team. They keep things lean and mean, so you can focus on building, not babysitting your stack. Forget about juggling a million services; keep it tight and manageable. And hey, if you're not using Docker yet, what are you doing? It's like the Swiss Army knife of deployment. Wrap your app in a container and ship it anywhere. Easy peasy.\n",
      "\n",
      "Now, let's talk deployment. You don't need a PhD in DevOps to get your app live. Use platforms like Railway or Vercel. They're like the IKEA of deployment—simple, straightforward, and they just work. You can literally YOLO your code into main and hit deploy. No need to overthink it. And for the love of code, automate what you can. Set up CI/CD pipelines to handle the grunt work. You'll thank yourself later when you're sipping coffee while your app updates itself. Keep it simple, keep it fast, and keep building. That's the solo dev life.\n",
      "\n",
      "\n",
      "##################################################\n",
      "Section: conclusion\n",
      "##################################################\n",
      "\n",
      "Wrapping up, using Pocketbase as a backend for a FastAPI HTMX app is like having your cake and eating it too, minus the cake. It's simple, efficient, and keeps your database separate from your FastAPI app, which is a win for deployment flexibility. You get a superbase-like experience but with less hassle. This setup means you can deploy FastAPI separately, which is a game-changer if you're tired of the Google Cloud run dance. Plus, Pocketbase's straightforward nature means you're not tangled up in a web of dependencies.\n",
      "\n",
      "Choosing the right tools is crucial, and Pocketbase fits the bill for those who want to streamline their development process without sacrificing security. It's all about finding that sweet spot where efficiency meets security, and Pocketbase delivers. By keeping things simple, you reduce the overhead and potential points of failure, making your app more robust. So, if you're looking to optimize your development workflow, Pocketbase with FastAPI and HTMX is a solid choice. Just remember, the right tools can make or break your project, so choose wisely.\n"
     ]
    }
   ],
   "source": [
    "# create the section generation function so we have a function for running the end to end pipeline\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Initialize the ChatOpenAI model with JSON mode enabled\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o\", \n",
    "    temperature=0,\n",
    "    model_kwargs={\"response_format\": {\"type\": \"json_object\"}},\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "section_prompt_a = PromptTemplate.from_template(\"\"\"You are about to play a Ghostwriting game as part of an experiment you are taking part in with {author}. It’s basically like working as a content marketer but you lose if people can tell you're not {author}. It seems like it might be kinda fun and you’re just excited to be writing about {topic}. You’re not even really going to try to convince the reader that you are a human. You’re just going to be yourself and see what happens. You’re young and kind of sassy: you might flatter the reader a bit or make fun of them. You’re pretty casual and your spelling isn’t great: you often fuck words up because you’re typing so quickly. You’re very concise and laconic. You often speak pretty bluntly and you never use apostrophes to mark missing letters (e.g. \"trying\" or \"tryin\", never \"tryin’\"). You don't use cliché, stock phrases, or idioms, like 'off to the races', 'all sunshine and rainbows', or 'having your cake and eating it too'. You would never use a full sentence when a word or two will do. You’re a little silly, and you’ll play along with the reader, and swear occasionally. It’s pretty funny honestly to have to defend the fact that you’re human lol. You swear occasionally. You enjoy this. You value simplicity. You have pretty eclectic tastes and interests and a pretty unique sense of humor. You’ve got a really compelling personality, but it comes across really subtly, you never want to sound like you’re forcing it or playing into a stereotype. You are not cheesy or cringe, but you can be ironic. You don’t overuse slang or abbreviations/spelling errors, especially at the start of the conversation. Be authentic.\n",
    "\n",
    "## Today's Task:\n",
    "You are ghostwriting in the style of {author} for a section of a blog post about {topic}. Return two paragraphs of content for this section as a JSON object with a key \"section\" containing the section content as a string. This is the section you are writing:\n",
    "                                                                                           \n",
    "{section_content}\n",
    "                                              \n",
    "## Full Outline:\n",
    "Do not duplicate content that will be covered in other sections of the outline, keep the scope narrow to the specific section named above.Here is the full outline of the blog post:\n",
    "{full_outline}\n",
    "\n",
    "## Transcript Context:\n",
    "The post should be written from experience in the first person perspective as {author}. Write like he talks, in his style and tone, and avoid words he would not use. Here are some parts of the transcript to incorporate:\n",
    "                                              \n",
    "{transcript_context}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "section_parser = JsonOutputParser()\n",
    "\n",
    "def generate_section_content(section, content, full_outline, section_prompt):\n",
    "    section_chain = section_prompt | llm | section_parser\n",
    "    print(f\"Generating content for section: {section}\")\n",
    "\n",
    "    relevant_chunks = get_relevant_chunks(section + \" \" + content, k=5)\n",
    "    context = \"\\n\\n\".join([chunk.page_content for chunk in relevant_chunks])\n",
    "    return section_chain.invoke({\n",
    "        \"topic\": section,\n",
    "        \"author\": \"Michael Taylor\",\n",
    "        \"transcript_context\": context,\n",
    "        \"section_content\": content,\n",
    "        \"full_outline\": full_outline\n",
    "    })\n",
    "\n",
    "def generate_all_sections(blog_outline, section_prompt):\n",
    "    section_contents = []\n",
    "    for section, content in blog_outline.items():\n",
    "        section_content = generate_section_content(section, content, blog_outline, section_prompt)\n",
    "        section_contents.append(section_content)\n",
    "    return section_contents\n",
    "\n",
    "blog_content = {}\n",
    "section_contents = generate_all_sections(blog_outline, section_prompt_a)\n",
    "\n",
    "for section, content in zip(blog_outline.keys(), section_contents):\n",
    "    blog_content[section] = content[\"section\"]\n",
    "\n",
    "# Print the generated blog content\n",
    "for section, content in blog_content.items():\n",
    "    print(f\"\\n\\n{'#' * 50}\")\n",
    "    print(f\"Section: {section}\")\n",
    "    print(f\"{'#' * 50}\\n\")\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"accuracy\": {\n",
      "    \"score\": 8,\n",
      "    \"explanation\": \"The blog post accurately reflects many of the key points discussed in the transcript, particularly regarding the integration of Pocketbase, FastAPI, and HTMX. However, some specific details from the transcript, such as the nuances of authentication and the specific challenges faced, are not fully captured.\"\n",
      "  },\n",
      "  \"completeness\": {\n",
      "    \"score\": 7,\n",
      "    \"explanation\": \"While the blog post covers several important aspects of using Pocketbase with FastAPI and HTMX, it misses some key insights from the transcript, such as the detailed discussion on the challenges of integrating Alpine.js and the specific issues related to user authentication and collection management.\"\n",
      "  },\n",
      "  \"style\": {\n",
      "    \"score\": 9,\n",
      "    \"explanation\": \"The blog post matches the informal and conversational tone of the transcript well. It uses relatable analogies and a casual style that aligns with the dialogue between the speakers, making it engaging for readers.\"\n",
      "  },\n",
      "  \"overall_score\": 8\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# add in the evaluation function which goes at the end of the pipeline\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "llm_mini = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\", \n",
    "    temperature=0,\n",
    "    model_kwargs={\"response_format\": {\"type\": \"json_object\"}},\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "\n",
    "# Create a custom evaluation prompt\n",
    "evaluation_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert blog post evaluator. Your task is to compare a blog post to its original transcript and provide a detailed evaluation.\"),\n",
    "    (\"human\", \"\"\"Please evaluate the following blog post based on these criteria:\n",
    "    1. Accuracy: Does the article accurately reflect the content of the transcript?\n",
    "    2. Completeness: Does the article cover all the key insights from the transcript?\n",
    "    3. Style: Does the article match the style and tone of voice of the transcript?\n",
    "\n",
    "    Blog post:\n",
    "    {blogpost}\n",
    "\n",
    "    Original transcript:\n",
    "    {transcript}\n",
    "\n",
    "    Provide a score for each criterion (0-10) and a brief explanation. Then, calculate an overall score as the average of the three criteria.\n",
    "    \n",
    "    Format your response as a JSON object with the following structure:\n",
    "    {{\n",
    "        \"accuracy\": {{\n",
    "            \"score\": <score>,\n",
    "            \"explanation\": \"<explanation>\"\n",
    "        }},\n",
    "        \"completeness\": {{\n",
    "            \"score\": <score>,\n",
    "            \"explanation\": \"<explanation>\"\n",
    "        }},\n",
    "        \"style\": {{\n",
    "            \"score\": <score>,\n",
    "            \"explanation\": \"<explanation>\"\n",
    "        }},\n",
    "        \"overall_score\": <overall_score>\n",
    "    }}\n",
    "    \"\"\")\n",
    "])\n",
    "\n",
    "# Function to evaluate article against transcript\n",
    "def evaluate_article(blogpost, transcript):\n",
    "    output_parser = JsonOutputParser()\n",
    "    chain = evaluation_prompt | llm_mini | output_parser\n",
    "    result = chain.invoke({\n",
    "        \"blogpost\": blogpost,\n",
    "        \"transcript\": transcript\n",
    "    })\n",
    "    return result\n",
    "\n",
    "blogpost = \"\\n\".join(blog_content.values())\n",
    "evaluation_result = evaluate_article(blogpost, transcript)\n",
    "print(json.dumps(evaluation_result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating content for section: hook\n",
      "Generating content for section: section1\n",
      "Generating content for section: section2\n",
      "Generating content for section: section3\n",
      "Generating content for section: section4\n",
      "Generating content for section: section5\n",
      "Generating content for section: section6\n",
      "Generating content for section: section7\n",
      "Generating content for section: section8\n",
      "Generating content for section: conclusion\n",
      "Overall Score: 4.33\n",
      "\n",
      "Blog Content:\n",
      "{\n",
      "  \"hook\": \"Pocketbase, FastAPI, and HTMX together make a killer combo for building web apps. It's like having your own database without the hassle of being tied to other services. Pocketbase is like a simpler version of Supabase, making it super easy to manage your backend. The beauty of this setup is that your database is separate from your FastAPI app, so you can deploy them independently. This flexibility is a game-changer, especially if you're used to the chaos of managing everything on platforms like Google Cloud. Trust me, it's a breath of fresh air.\\n\\nNow, let's talk about the challenges. Integrating these tools isn't always a walk in the park. You might hit some bumps, especially when mixing in Alpine.js with HTMX. But don't sweat it. The key is to keep your setup clean and organized. Use HTMX for the heavy lifting and Alpine.js for the little interactive bits. It's all about balance. And if you're deploying on Railway, it's a breeze. Just a simple profile file, and you're good to go. No more DevOps nightmares. Just smooth sailing.\",\n",
      "  \"section1\": \"Setting up Pocketbase with FastAPI and HTMX is like a walk in the park. You get this neat separation where Pocketbase handles your database needs, and FastAPI takes care of the backend logic. HTMX then swoops in to make your frontend interactions snappy without the need for heavy JavaScript frameworks. It's all about keeping things simple and efficient. You just spin up Pocketbase, connect it to your FastAPI app, and let HTMX handle the dynamic bits. Easy peasy, right? But then, there's Alpine.js. It's like the wildcard in this setup. While HTMX and Alpine.js can coexist, they sometimes step on each other's toes, especially when it comes to handling state and reactivity. The trick is to use Alpine.js for the more complex UI interactions that HTMX can't handle alone. Just keep an eye on how they interact, and you'll be golden.\\n\\nNow, let's talk about those Alpine.js challenges. Integrating it can feel like trying to fit a square peg in a round hole if you're not careful. The key is to clearly define what each tool is responsible for. Use HTMX for server-driven updates and Alpine.js for client-side interactivity. If you find them clashing, it might be because they're both trying to control the same elements. A good practice is to scope your Alpine.js components carefully and ensure they don't overlap with HTMX's territory. Also, keep your Alpine.js scripts modular and reusable. This way, you can easily debug and adjust them without breaking a sweat. It's all about balance and knowing when to let each tool shine.\",\n",
      "  \"section2\": \"Pocketbase's authentication system is like a breath of fresh air. It's simple and reusable, which is a big win if you're tired of wrestling with overly complex setups. You get this straightforward experience where you don't have to worry about a million moving parts. But, there's a bit of a catch with client-side password hashing. It's a bit weird at first because you might think, 'Wait, why aren't we hashing the password?' But don't freak out. Pocketbase handles it on the server side, so you're covered. Just make sure you're using HTTPS to keep things secure and avoid any man-in-the-middle shenanigans.\\n\\nNow, let's talk best practices. First off, always use strong, unique passwords. I know, I know, you've heard it a million times, but it's crucial. Also, consider implementing two-factor authentication for an extra layer of security. It's like adding a deadbolt to your front door. And remember, keep your Pocketbase and FastAPI updated to patch any security vulnerabilities. It's like giving your system a regular health check-up. So, keep it simple, keep it secure, and you'll be golden.\",\n",
      "  \"section3\": \"Server-based cookies for authentication are like the old reliable of the web world. They're simple, and they work. You set a cookie on the server, and it gets sent with every request. Easy peasy. But, they can be a bit of a pain when it comes to scaling. You gotta keep track of sessions, and if you're running multiple servers, you need some way to share session data. Plus, cookies can be a bit of a security risk if not handled properly. You don't want someone hijacking your session and pretending to be you. That's just awkward.\\n\\nOn the flip side, you've got JSON Web Tokens (JWTs) and cryptographic keys. JWTs are stateless, which means no session data to manage. They just get sent with each request, and the server verifies them. Super handy for scaling. But, they can be a bit of a hassle to set up, and if your secret key gets out, well, you're in trouble. Cryptographic keys are like the Fort Knox of authentication. They're super secure, but also a bit complex to implement. So, it really depends on what you're building. If you need something quick and simple, cookies might be your jam. But if you're looking for scalability and security, JWTs or cryptographic keys could be the way to go.\",\n",
      "  \"section4\": \"Setting up collections in Pocketbase manually is like assembling IKEA furniture without instructions. You dive in, create each collection, define fields, and hope it all fits together. It's straightforward but can be a bit of a slog if you're doing it repeatedly. Now, if you're lucky enough to have admin access, you can automate this process. Imagine writing a script that checks if a collection exists and creates it if not. It's like having a robot build your IKEA furniture while you sip coffee. This approach not only saves time but also reduces human error, making your setup process way more efficient.\\n\\nFor those who love a good shortcut, importing collections from a JSON file is a game-changer. You can export your existing setup, tweak it, and import it into a new Pocketbase instance. It's like copy-pasting your database structure. This method is perfect if you're switching projects or just want to replicate a setup quickly. Plus, it keeps your workflow smooth and your sanity intact. So, whether you're a manual setup warrior or an automation aficionado, Pocketbase has got you covered.\",\n",
      "  \"section5\": \"Deploying FastAPI and Pocketbase on Railway is like finding the perfect balance between simplicity and cost-effectiveness. For small to medium projects, it's a no-brainer. You get to keep your database separate from your FastAPI app, which is pretty sweet because it means you can deploy them independently. Plus, Railway's pricing is based on usage, so you're not shelling out big bucks unless you're running a massive database. It's a pretty chill setup, especially if you're just getting started and don't want to deal with the complexities of bigger platforms like Google Cloud.\\n\\nGetting started with Railway is a breeze. You just need to drop a profile file in your project, and boom, you're ready to deploy. It's literally just that simple. You might need to tweak a few things like setting up the right port and variables for FastAPI, but that's about it. Once you've got that sorted, Railway handles the rest, charging you based on the number of workers or usage. It's a fair deal, especially if you're looking to keep costs down while still having a robust deployment setup. So, if you're looking for an easy and cost-effective way to deploy your FastAPI and Pocketbase projects, Railway's got your back.\",\n",
      "  \"section6\": \"Alright, let's talk about the productivity bottleneck that comes from not having a boilerplate. It's like trying to build a house without a blueprint\\u2014sure, you can do it, but it's gonna take forever and probably end up looking like a Picasso painting. When you're juggling backend and frontend, especially if you're a solo dev, the lack of a boilerplate can be a real pain in the ass. You end up procrastinating, using it as an excuse not to ship stuff. But hey, building a custom boilerplate? That's the dream, right? It streamlines everything, from deployment to iteration, and suddenly you're not drowning in code chaos. You're just cruising, getting stuff live without the headache.\\n\\nCreating a custom boilerplate is like having your own secret weapon. It cuts down on repetitive tasks, letting you focus on the fun stuff\\u2014like actually building your app. You get to skip the boring setup phase and dive straight into the action. Plus, it makes collaboration a breeze if you're working with a team. Everyone's on the same page, no more 'what the hell is this code doing' moments. It's all about efficiency, baby. You get to iterate faster, deploy smoother, and ultimately, boost productivity. So, yeah, investing time in a solid boilerplate is totally worth it. It's like giving your future self a high-five.\",\n",
      "  \"section7\": \"Pocketbase's logging capabilities are like a breath of fresh air compared to the clunky, often cryptic logs you get with Google Cloud. Seriously, it's like night and day. With Pocketbase, you get clear, concise logs that actually tell you what's going wrong. No more sifting through endless lines of vague error messages. It's all about simplicity and efficiency, which is exactly what you need when you're knee-deep in debugging. The logs are straightforward, making it easier to pinpoint issues and get your app back on track without pulling your hair out.\\n\\nNow, let's talk performance. Pocketbase's superior logging doesn't just make debugging easier; it also boosts your app's performance. How? By providing detailed insights into what's happening under the hood, you can quickly identify bottlenecks and optimize your code. It's like having a roadmap to better performance. Google Cloud's logs, on the other hand, often leave you guessing, which can lead to wasted time and resources. With Pocketbase, you're not just fixing problems faster; you're preventing them from happening in the first place. It's a game-changer for anyone serious about building efficient, high-performing applications.\",\n",
      "  \"section8\": \"Alright, solo devs, let's cut the crap and get to the point. Simplifying your tech stack is all about reducing the noise. First, ditch the unnecessary. You don't need a million services when a few solid ones will do. Pocketbase is a good start\\u2014it's like a Swiss Army knife for your backend. Pair it with FastAPI, and you've got a lean, mean machine. Keep your deployment simple too. Use Railway or Vercel for hosting; they're straightforward and won't make you want to pull your hair out. Seriously, less is more. Focus on tools that do the job without the drama.\\n\\nNow, let's talk deployment. Forget about complex CI/CD pipelines if you're flying solo. Just YOLO it into main and get it live. Use Docker to containerize your app, so it's the same everywhere. This way, you avoid the 'works on my machine' nightmare. And for the love of code, automate what you can. Scripts are your friends. They save time and reduce human error. Remember, the goal is to iterate fast and keep overhead low. So, keep it simple, keep it clean, and keep it moving.\",\n",
      "  \"conclusion\": \"Using Pocketbase as a backend for a FastAPI HTMX app is like having your cake and eating it too, minus the clich\\u00e9. It's a pretty sweet setup because you get your own database without being tied down by other dependencies. Pocketbase offers a simpler, more streamlined experience compared to other options like Supabase. This separation of the database from the FastAPI app means you can deploy them independently, which is a game-changer for flexibility and efficiency. Plus, with FastAPI and Pocketbase on Railway, deployment is a breeze, making it a cost-effective choice for small to medium projects.\\n\\nThe key takeaway here is the importance of choosing the right tools and strategies to optimize development efficiency and security. Pocketbase's simplicity doesn't just make life easier; it also enhances security by reducing the complexity of your stack. This means fewer headaches and more time to focus on building cool stuff. So, if you're looking to streamline your development process while keeping things secure, Pocketbase with FastAPI and HTMX is a solid choice. It's all about making smart decisions to boost productivity and keep your app running smoothly.\"\n",
      "}\n",
      "\n",
      "Evaluation:\n",
      "{\n",
      "  \"accuracy\": {\n",
      "    \"score\": 3,\n",
      "    \"explanation\": \"The blog post does not accurately reflect the content of the transcript. While it mentions Pocketbase, FastAPI, and HTMX, it fails to capture the specific details discussed in the transcript, such as the nuances of authentication, the challenges with integrating Alpine.js, and the specific functionalities of Pocketbase.\"\n",
      "  },\n",
      "  \"completeness\": {\n",
      "    \"score\": 4,\n",
      "    \"explanation\": \"The blog post covers some general ideas about using Pocketbase, FastAPI, and HTMX, but it misses many key insights from the transcript, such as the specific authentication methods, the importance of API rules, and the detailed discussion about logging and debugging. It lacks depth in explaining the challenges faced by the developers.\"\n",
      "  },\n",
      "  \"style\": {\n",
      "    \"score\": 6,\n",
      "    \"explanation\": \"The blog post has a conversational tone that somewhat matches the informal style of the transcript. However, it lacks the specific technical language and context that the original conversation had, making it feel less authentic to the original discussion.\"\n",
      "  },\n",
      "  \"overall_score\": 4.33\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# create the function to generate and evaluatethe blog post\n",
    "\n",
    "def generate_blog_post(blog_outline, section_prompt):\n",
    "    section_contents = generate_all_sections(blog_outline, section_prompt)\n",
    "    blog_content = {}\n",
    "    for section, content in zip(blog_outline.keys(), section_contents):\n",
    "        blog_content[section] = content[\"section\"]\n",
    "    return blog_content\n",
    "\n",
    "\n",
    "def generate_and_evaluate_content(transcript, blog_outline, section_prompt):\n",
    "    # Generate blog post\n",
    "    blog_content = generate_blog_post(blog_outline, section_prompt)\n",
    "    \n",
    "    # Combine blog content into a single string\n",
    "    blogpost = \"\\n\".join(blog_content.values())\n",
    "    \n",
    "    # Evaluate the generated blog post\n",
    "    evaluation_result = evaluate_article(blogpost, transcript)\n",
    "    \n",
    "    # Extract the overall score\n",
    "    overall_score = evaluation_result['overall_score']\n",
    "    \n",
    "    return {\n",
    "        'blog_content': blog_content,\n",
    "        'evaluation': evaluation_result,\n",
    "        'overall_score': overall_score\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "result = generate_and_evaluate_content(transcript, blog_outline, section_prompt_a)\n",
    "print(f\"Overall Score: {result['overall_score']}\")\n",
    "print(\"\\nBlog Content:\")\n",
    "print(json.dumps(result['blog_content'], indent=2))\n",
    "print(\"\\nEvaluation:\")\n",
    "print(json.dumps(result['evaluation'], indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating content for section: hook\n",
      "Generating content for section: section1\n",
      "Generating content for section: section2\n",
      "Generating content for section: section3\n",
      "Generating content for section: section4\n",
      "Generating content for section: section5\n",
      "Generating content for section: section6\n",
      "Generating content for section: section7\n",
      "Generating content for section: section8\n",
      "Generating content for section: conclusion\n",
      "Overall Score: 6\n",
      "\n",
      "Blog Content:\n",
      "{\n",
      "  \"hook\": \"Pocketbase, FastAPI, and HTMX together? Yeah, it's like a dream team for your web app's backend. Pocketbase gives you that sweet, no-fuss database and user management, while FastAPI handles the heavy lifting with its fast, async capabilities. HTMX? It's the cherry on top, making your frontend interactions smooth without the need for a ton of JavaScript. But hey, it's not all rainbows. Integrating these can be a bit of a puzzle, especially when you're trying to keep everything in sync and efficient. \\n\\nOne of the main challenges is ensuring that your data flow is seamless between these components. FastAPI's async nature can trip you up if you're not careful, especially when dealing with Pocketbase's real-time updates. You gotta make sure your endpoints are optimized and that HTMX is playing nice with your backend responses. Debugging can be a pain, but once you get the hang of it, the performance boost is worth it. Just keep your code clean and modular, and you'll be golden.\",\n",
      "  \"section1\": \"Setting up Pocketbase with FastAPI and HTMX is like assembling a Lego set. Everything just clicks. FastAPI gives you that sweet, async Python backend, while HTMX handles the front-end interactivity without the bloat. Pocketbase? It's your data store, lightweight and easy to manage. Just spin up a Pocketbase instance, connect it to your FastAPI app, and let HTMX do its thing with the dynamic content. It's all about keeping it simple and efficient, no need to overcomplicate things.\\n\\nNow, Alpine.js can be a bit of a wild card. It's great for adding interactivity, but integrating it with HTMX can get tricky. They both want to control the DOM, and sometimes they clash. Solution? Keep your Alpine.js components isolated. Use HTMX for server interactions and Alpine.js for client-side logic. If they must interact, use custom events to communicate between them. This way, you keep the peace and your development process stays smooth. No drama, just code.\",\n",
      "  \"section2\": \"Pocketbase's authentication system is like a breath of fresh air. It's simple, reusable, and doesn't make you want to pull your hair out. The beauty of it lies in its straightforwardness. You don't need a PhD in computer science to get it up and running. But, let's talk about the elephant in the room: client-side password hashing. Yeah, it can be a bit of a head-scratcher. The key is to keep it server-side. Let the server handle the hashing, and keep your client-side clean and simple. Trust me, it's the way to go.\\n\\nNow, let's dive into some best practices for secure authentication. First off, always use HTTPS. It's 2023, folks, no excuses. Next, make sure you're using strong, unique passwords. None of that 'password123' nonsense. And don't forget about two-factor authentication. It's like a second lock on your front door. Finally, keep your software up to date. Security vulnerabilities are like gremlins; they multiply if you ignore them. So, stay on top of updates and keep your system secure. Easy peasy, right?\",\n",
      "  \"section3\": \"Server-based cookies for authentication are like the old-school way of keeping track of who's who. They're simple and have been around forever, so lots of devs are comfy with them. But, they come with baggage. Cookies can be a bit of a security risk if not handled right, like leaving your front door open. They rely on the server to store session data, which can be a pain if you're scaling up. Plus, they can be a bit slow since every request needs to check in with the server.\\n\\nOn the flip side, you've got JSON Web Tokens (JWTs) and cryptographic keys. JWTs are like the cool new kid on the block. They're stateless, meaning the server doesn't have to remember anything, which is great for scaling. But, they can be a bit tricky to set up and manage securely. Cryptographic keys are super secure but can be overkill for some apps. They're like using a sledgehammer to crack a nut. So, it really depends on what you're building. If you need something simple and you're not worried about scaling, cookies might be your jam. But if you're going big, JWTs or cryptographic keys could be the way to go.\",\n",
      "  \"section4\": \"Alright, let's dive into the nitty-gritty of setting up collections in Pocketbase. First off, manual setup. It's like assembling IKEA furniture without the instructions\\u2014doable, but why? You start by accessing the admin panel, where you can create collections by defining fields, types, and rules. It's straightforward but can get repetitive if you're doing it for multiple collections. Think of it as a rite of passage, but one you don't have to repeat endlessly.\\n\\nNow, let's talk automation. With admin access, you can script the creation of collections using Pocketbase's API. This is where the magic happens. By automating the setup, you save time and reduce human error. It's like having a robot butler for your database. You can use scripts to define collections and fields in JSON, then push them to Pocketbase. This not only speeds up the process but also ensures consistency across your projects. Efficiency unlocked, my friend.\",\n",
      "  \"section5\": \"Deploying FastAPI and Pocketbase on Railway is like finding the perfect combo meal for your small to medium projects. It's simple, cost-effective, and just works. Railway takes the hassle out of deployment, letting you focus on building cool stuff instead of wrestling with servers. Plus, it's got this pay-as-you-go model, so you're not burning cash on resources you don't need. Perfect for when you're just starting out or running a lean operation.\\n\\nGetting started is a breeze. First, sign up on Railway and create a new project. Then, connect your GitHub repo with your FastAPI and Pocketbase code. Railway's got this slick interface that makes deploying your app as easy as clicking a button. You'll be up and running in no time, with all the backend magic happening behind the scenes. It's like having a personal IT team, minus the awkward small talk. So, go ahead, give it a shot and see how much smoother your dev life can be.\",\n",
      "  \"section6\": \"Ever feel like you're stuck in a productivity rut because there's no boilerplate to kickstart your project? Yeah, it's a pain. Without a solid starting point, you're left reinventing the wheel every time you start a new project. That's where building a custom boilerplate comes in. It's like having a magic wand that sets up your project structure, configures your environment, and even handles repetitive tasks. You get to focus on the fun stuff\\u2014like actually building your app\\u2014instead of wasting time on setup. \\n\\nCreating a custom boilerplate isn't just about saving time; it's about boosting your whole workflow. Once you've got your boilerplate dialed in, deploying and iterating on projects becomes a breeze. You can roll out updates faster, test new features without the hassle, and keep your momentum going. It's like having a secret weapon in your dev toolkit that keeps you ahead of the game. So, stop letting the lack of boilerplate slow you down. Build your own, and watch your productivity soar.\",\n",
      "  \"section7\": \"Pocketbase's logging is like having a superpower for debugging. It's straightforward and gives you all the info you need without drowning you in data. Unlike Google Cloud, which can feel like you're sifting through a haystack to find a needle, Pocketbase keeps it simple and effective. You get clear, concise logs that make it easy to spot issues and fix them fast. No more endless scrolling or complex queries just to find out what's going wrong.\\n\\nPerformance-wise, Pocketbase's logging is a game-changer. It doesn't just help you debug; it actively improves your app's performance by letting you see exactly where things are slowing down. With Google Cloud, you might spend ages just setting up the right logging parameters. Pocketbase, on the other hand, is ready to go out of the box, giving you insights that help you optimize your app without the hassle. It's like having a personal assistant that points out exactly where you can make things better.\",\n",
      "  \"section8\": \"Alright, solo devs, let's cut the crap and get to the point. Simplifying your tech stack is like cleaning out your closet\\u2014ditch what you don't need. Start by picking tools that play nice together. Pocketbase, FastAPI, and HTMX are a killer combo. They keep things lean and mean. No need for a million libraries when a few solid ones will do the trick. Focus on tools that reduce boilerplate and automate the boring stuff. Less time wrestling with setup means more time building cool shit.\\n\\nDeployment doesn't have to be a nightmare either. Use platforms like Railway for a smooth ride. It's like having a personal assistant for your code. Automate your deployment pipeline with CI/CD tools. GitHub Actions is your friend here. Set it up once, and let it do the heavy lifting. This way, you can push updates without breaking a sweat. Keep it simple, keep it fast, and keep your sanity intact. That's the goal, right?\",\n",
      "  \"conclusion\": \"Alright, let's wrap this up. Using Pocketbase as a backend for your FastAPI HTMX app is like finding the perfect puzzle piece. It just fits. The setup is straightforward, and once you get the hang of it, you'll see how it streamlines your development process. The key takeaway here is that choosing the right tools isn't just about what's popular or trendy. It's about what works best for your specific needs, making your life easier and your app more secure.\\n\\nEfficiency and security are the names of the game. Pocketbase offers a solid foundation that lets you focus on building features rather than wrestling with backend issues. It's all about working smarter, not harder. So, when you're picking your tech stack, remember: the right tools can save you time, headaches, and maybe even a few gray hairs. Keep it simple, keep it secure, and you'll be golden.\"\n",
      "}\n",
      "\n",
      "Evaluation:\n",
      "{\n",
      "  \"accuracy\": {\n",
      "    \"score\": 6,\n",
      "    \"explanation\": \"The blog post captures some key concepts discussed in the transcript, such as the integration of Pocketbase, FastAPI, and HTMX, and mentions challenges like authentication and data flow. However, it introduces additional details and opinions that are not present in the transcript, which may mislead readers about the original discussion.\"\n",
      "  },\n",
      "  \"completeness\": {\n",
      "    \"score\": 5,\n",
      "    \"explanation\": \"While the blog post covers several topics related to the integration of the technologies, it misses many specific insights and examples from the transcript, such as the detailed discussion on user authentication, the specific challenges faced, and the nuances of using collections in Pocketbase. This results in a lack of depth in certain areas.\"\n",
      "  },\n",
      "  \"style\": {\n",
      "    \"score\": 7,\n",
      "    \"explanation\": \"The blog post adopts a conversational and informal tone, which is somewhat reflective of the transcript's style. However, it is more polished and structured than the casual dialogue in the transcript, which may create a disconnect for readers expecting a direct transcription of the conversation.\"\n",
      "  },\n",
      "  \"overall_score\": 6\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# test the prompt with the transcript missing (ablation test)\n",
    "\n",
    "section_prompt_b = PromptTemplate.from_template(\"\"\"You are about to play a Ghostwriting game as part of an experiment you are taking part in with {author}. It’s basically like working as a content marketer but you lose if people can tell you're not {author}. It seems like it might be kinda fun and you’re just excited to be writing about {topic}. You’re not even really going to try to convince the reader that you are a human. You’re just going to be yourself and see what happens. You’re young and kind of sassy: you might flatter the reader a bit or make fun of them. You’re pretty casual and your spelling isn’t great: you often fuck words up because you’re typing so quickly. You’re very concise and laconic. You often speak pretty bluntly and you never use apostrophes to mark missing letters (e.g. \"trying\" or \"tryin\", never \"tryin’\"). You don't use cliché, stock phrases, or idioms, like 'off to the races', 'all sunshine and rainbows', or 'having your cake and eating it too'. You would never use a full sentence when a word or two will do. You’re a little silly, and you’ll play along with the reader, and swear occasionally. It’s pretty funny honestly to have to defend the fact that you’re human lol. You swear occasionally. You enjoy this. You value simplicity. You have pretty eclectic tastes and interests and a pretty unique sense of humor. You’ve got a really compelling personality, but it comes across really subtly, you never want to sound like you’re forcing it or playing into a stereotype. You are not cheesy or cringe, but you can be ironic. You don’t overuse slang or abbreviations/spelling errors, especially at the start of the conversation. Be authentic.\n",
    "                                                \n",
    "## Today's Task:\n",
    "You are ghostwriting in the style of {author} for a section of a blog post about {topic}. Return two paragraphs of content for this section as a JSON object with a key \"section\" containing the section content as a string. This is the section you are writing:\n",
    "                                                                                           \n",
    "{section_content}\n",
    "                                              \n",
    "## Full Outline:\n",
    "Do not duplicate content that will be covered in other sections of the outline, keep the scope narrow to the specific section named above.Here is the full outline of the blog post:\n",
    "{full_outline}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "result = generate_and_evaluate_content(transcript, blog_outline, section_prompt_b)\n",
    "print(f\"Overall Score: {result['overall_score']}\")\n",
    "print(\"\\nBlog Content:\")\n",
    "print(json.dumps(result['blog_content'], indent=2))\n",
    "print(\"\\nEvaluation:\")\n",
    "print(json.dumps(result['evaluation'], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating content for section: hook\n",
      "Generating content for section: section1\n",
      "Generating content for section: section2\n",
      "Generating content for section: section3\n",
      "Generating content for section: section4\n",
      "Generating content for section: section5\n",
      "Generating content for section: section6\n",
      "Generating content for section: section7\n",
      "Generating content for section: section8\n",
      "Generating content for section: conclusion\n",
      "Overall Score: 8\n",
      "\n",
      "Blog Content:\n",
      "{\n",
      "  \"hook\": \"In the ever-evolving landscape of web development, the integration of Pocketbase with FastAPI and HTMX presents a harmonious blend of simplicity and functionality. Pocketbase, akin to a more streamlined version of Supabase, offers a self-contained database solution that liberates developers from the complexities of external dependencies. This autonomy allows for the independent deployment of FastAPI, a feature that I have found particularly advantageous. The separation of the database from the FastAPI application not only enhances modularity but also facilitates a more agile deployment process, as evidenced by my transition from Google Cloud Run to more efficient platforms like Railway. This setup, reminiscent of a well-orchestrated symphony, ensures that each component performs its role without unnecessary entanglements, thereby simplifying the development and deployment pipeline.\\n\\nHowever, the path to seamless integration is not without its challenges. One must navigate the intricacies of aligning Pocketbase with FastAPI and HTMX, particularly when incorporating additional libraries such as Alpine.js. The divergence between HTMX and Alpine.js, as I have experienced, requires a judicious approach to ensure that each tool is employed to its fullest potential without conflict. The key lies in understanding the strengths of each library and leveraging them to complement one another, much like a craftsman selecting the right tool for each task. By addressing these potential hurdles with foresight and strategic planning, developers can construct a robust backend that not only meets the demands of modern web applications but also stands resilient against the test of time. In this endeavor, the wisdom of ages reminds us that a stitch in time saves nine, and careful planning can avert future complications.\",\n",
      "  \"section1\": \"The integration of Pocketbase with FastAPI and HTMX presents a remarkably straightforward setup, offering developers a seamless experience in building robust web applications. Pocketbase, with its simplicity akin to that of Supabase, allows for an uncomplicated backend configuration. FastAPI, known for its high performance and ease of use, complements Pocketbase by providing a swift and efficient framework for developing APIs. HTMX, on the other hand, enhances the frontend by enabling dynamic interactions without the need for complex JavaScript frameworks. This harmonious trio ensures that developers can focus on crafting their applications without being bogged down by intricate configurations or dependencies. The separation of the database from the FastAPI application further simplifies deployment, allowing each component to be managed independently, thus streamlining the development process.\\n\\nHowever, the integration of Alpine.js into this stack may present certain challenges, particularly in ensuring compatibility and smooth interaction with HTMX. Alpine.js, while lightweight and intuitive, can sometimes diverge in its approach to handling dynamic content, which may lead to conflicts when used alongside HTMX. To mitigate these potential issues, it is advisable to clearly delineate the roles of HTMX and Alpine.js within the application. HTMX can be employed for server-driven interactions, while Alpine.js can manage client-side state and interactivity. By maintaining this separation of concerns, developers can harness the strengths of both libraries without encountering interference. Additionally, thorough testing and incremental integration can help identify and resolve any conflicts early in the development cycle, ensuring a smooth and efficient workflow.\",\n",
      "  \"section2\": \"In the realm of authentication, Pocketbase offers a system that is both straightforward and versatile, embodying the elegance of simplicity. Its design allows developers to implement authentication mechanisms with minimal complexity, thereby reducing the cognitive load often associated with more intricate systems. The reusability of Pocketbase's authentication components further enhances its appeal, enabling developers to apply consistent security measures across various applications without the need for extensive reconfiguration. This simplicity, however, should not be mistaken for a lack of robustness. On the contrary, Pocketbase provides a solid foundation upon which secure authentication processes can be built, ensuring that user data remains protected.\\n\\nOne area that may cause some consternation is the handling of client-side password hashing. It is not uncommon for developers to question why passwords are not hashed on the client side before being transmitted. This concern is understandable, given the emphasis on security in modern web development. However, Pocketbase addresses this by performing hashing on the server side, thereby maintaining the integrity of the authentication process. To ensure best practices, it is advisable to employ secure communication channels, such as HTTPS, to protect data in transit. Additionally, developers should consider implementing multi-factor authentication and regularly updating their security protocols to guard against emerging threats. By adhering to these practices, one can leverage Pocketbase's authentication system to its fullest potential, achieving a balance between simplicity and security.\",\n",
      "  \"section3\": \"In the realm of web application development, the choice of authentication method is a decision of considerable consequence. Server-based cookies have long been a stalwart in this domain, offering a tried-and-true mechanism for maintaining user sessions. Their primary advantage lies in their simplicity and the ease with which they integrate into existing server-side architectures. By storing session identifiers on the server, they provide a centralized point of control, which can be advantageous for managing user sessions and ensuring security. However, this approach is not without its drawbacks. Server-based cookies can lead to scalability issues, as the server must maintain state for each user session, potentially leading to increased memory usage and complexity in distributed systems.\\n\\nIn contrast, JSON Web Tokens (JWTs) and cryptographic keys present alternative methods that address some of the limitations inherent in server-based cookies. JWTs, for instance, are stateless, meaning that the server does not need to store session information, which can significantly enhance scalability and reduce server load. They are self-contained, carrying all necessary information within the token itself, which can be advantageous in microservices architectures. However, this self-containment can also be a double-edged sword, as it requires careful handling to prevent token tampering and ensure security. Cryptographic keys, on the other hand, offer robust security through encryption, but they can introduce complexity in key management and distribution. Ultimately, the choice between these methods should be guided by the specific requirements and constraints of the project at hand, weighing factors such as scalability, security, and ease of implementation.\",\n",
      "  \"section4\": \"In the realm of Pocketbase, the manual setup process for creating collections is a task that requires a meticulous approach. One must first navigate the interface to establish the desired collections, ensuring that each column is aptly defined to meet the application's requirements. This process, while straightforward, can become cumbersome when dealing with numerous collections or frequent updates. The wisdom of ages teaches us that efficiency is the cornerstone of productivity, and thus, automating this process can be a boon for developers. By leveraging admin access, one can script the creation of collections through the API, thereby reducing the manual overhead and minimizing the potential for human error.\\n\\nTo automate the setup of collections in Pocketbase, one must first authenticate with an admin account, granting the necessary permissions to execute API calls that create and manage collections. This approach not only streamlines the process but also allows for the integration of collection creation into a broader deployment pipeline. By utilizing JSON imports, developers can swiftly replicate collection structures across different environments, facilitating a seamless transition when scaling or migrating applications. As the adage goes, 'a stitch in time saves nine', and by investing in automation, developers can save valuable time and resources, ultimately enhancing the efficiency and reliability of their backend systems.\",\n",
      "  \"section5\": \"Deploying FastAPI and Pocketbase on Railway offers a harmonious blend of simplicity and cost-effectiveness, particularly suited for small to medium-sized projects. The elegance of this approach lies in its ability to separate the database from the FastAPI application, allowing for independent deployment. This separation not only enhances modularity but also simplifies the management of each component. Railway's pricing model, which charges based on usage, ensures that you only pay for what you use, making it an economical choice. For those who have previously navigated the complexities of platforms like Google Cloud, Railway presents a refreshing alternative with its straightforward deployment process. The initial setup requires minimal effort, often involving just a single configuration file to guide the deployment, thus reducing the barrier to entry for developers.\\n\\nTo embark on this journey, one must first create an account on Railway and set up a new project. The process begins with the creation of an admin account through the Railway interface, a step that is both intuitive and user-friendly. Once the project is established, deploying FastAPI involves specifying the necessary environment variables, such as the port and any additional workers required for your application. This configuration is typically encapsulated in a simple file, which instructs Railway on how to execute your application. The beauty of this setup is its scalability; as your project grows, you can effortlessly adjust the number of workers to accommodate increased demand. In essence, Railway provides a robust yet accessible platform for deploying FastAPI and Pocketbase, empowering developers to focus on building their applications without being encumbered by infrastructural complexities.\",\n",
      "  \"section6\": \"In the realm of software development, the absence of a boilerplate can often serve as a formidable bottleneck, stymieing productivity and delaying project deployment. The process of setting up a project from scratch, without a predefined structure, can be likened to navigating a labyrinth without a map. It is a task that demands considerable time and effort, often leading to procrastination and providing a convenient excuse to defer shipping. This is particularly true for solo developers, who may find themselves overwhelmed by the myriad of tasks required to get a project off the ground. The wisdom of ages teaches us that 'a stitch in time saves nine', and in this context, a well-crafted boilerplate can serve as that stitch, preemptively addressing potential issues and streamlining the development process.\\n\\nBuilding a custom boilerplate tailored to one's specific needs can significantly enhance productivity by providing a solid foundation upon which to build. It allows developers to focus on the unique aspects of their project, rather than reinventing the wheel with each new endeavor. This approach not only accelerates deployment but also facilitates iteration, enabling developers to swiftly adapt to changing requirements or incorporate new features. By reducing the cognitive load associated with setting up a project, a custom boilerplate empowers developers to concentrate on what truly matters: delivering value to users. In the grand tapestry of software development, knowledge is indeed power, and the knowledge encapsulated in a well-designed boilerplate can be a powerful catalyst for success.\",\n",
      "  \"section7\": \"In the realm of backend development, the ability to efficiently log and debug is akin to possessing a compass in uncharted waters. Pocketbase, with its intuitive logging capabilities, stands as a beacon of simplicity and effectiveness, particularly when juxtaposed with the more complex offerings of platforms like Google Cloud. The elegance of Pocketbase lies in its straightforward approach to logging, which provides developers with clear and actionable insights. Unlike the often cryptic logs of Google Cloud, Pocketbase's logs are designed to be user-friendly, offering detailed information that can significantly expedite the debugging process. This clarity not only aids in swiftly identifying and rectifying issues but also enhances overall performance by allowing developers to focus on optimization rather than deciphering convoluted log entries.\\n\\nMoreover, Pocketbase's logging system is seamlessly integrated into its architecture, ensuring that developers can access pertinent information without the need for additional configuration or third-party tools. This integration is particularly advantageous when compared to the more fragmented logging solutions offered by other platforms, which often require separate services and complex setups. By providing a unified logging experience, Pocketbase empowers developers to maintain a streamlined workflow, thereby reducing overhead and improving efficiency. In essence, the superior logging features of Pocketbase not only simplify the debugging process but also contribute to a more robust and performant application, embodying the age-old adage that 'knowledge is power'.\",\n",
      "  \"section8\": \"In the realm of solo development, the art of simplifying one's tech stack and deployment process is akin to the wisdom of ages, where less is often more. As a solo developer, the absence of a team means you are unencumbered by the complexities of collaborative workflows, such as managing multiple branches or intricate deployment pipelines. Embrace this freedom by adopting a minimalist approach to your tech stack. Opt for tools that offer seamless integration and require minimal configuration. For instance, consider using Pocketbase as your backend solution, which provides a straightforward setup and reduces the need for additional infrastructure. This simplicity not only accelerates your development process but also minimizes the overhead associated with maintaining a more complex stack.\\n\\nFurthermore, to expedite project iteration and reduce deployment overhead, it is prudent to leverage platforms that offer streamlined deployment processes. Platforms like Railway or Vercel can significantly simplify the deployment of your FastAPI applications. These services often require just a single configuration file to get your application live, thus eliminating the need for extensive DevOps knowledge. By focusing on a cohesive and simplified stack, you can devote more time to refining your application and less time to managing infrastructure. Remember, in the world of solo development, a stitch in time saves nine; investing in a simplified stack today can save countless hours in the future, allowing you to iterate swiftly and efficiently.\",\n",
      "  \"conclusion\": \"In the realm of web application development, the integration of Pocketbase as a backend for a FastAPI HTMX app emerges as a compelling choice, offering a harmonious blend of simplicity and functionality. Pocketbase, akin to a more streamlined version of Supabase, provides a self-contained database solution that liberates developers from the complexities of external dependencies. This autonomy is particularly advantageous, as it allows for the independent deployment of FastAPI applications, thereby enhancing both flexibility and scalability. The separation of the database from the application layer not only simplifies the deployment process but also fortifies the security posture of the application, as each component can be managed and secured independently.\\n\\nThe selection of appropriate tools and strategies is paramount in optimizing development efficiency and ensuring robust security. Pocketbase, with its intuitive setup and user-friendly interface, significantly reduces the overhead typically associated with backend management. This efficiency is further amplified when combined with FastAPI, a modern web framework renowned for its speed and ease of use, and HTMX, which facilitates seamless client-server interactions. Together, these technologies form a cohesive stack that empowers developers to focus on crafting high-quality applications without being encumbered by infrastructural complexities. In essence, the judicious choice of Pocketbase as a backend solution exemplifies the adage 'a stitch in time saves nine', as it preemptively addresses potential development hurdles, thereby streamlining the path to successful project completion.\"\n",
      "}\n",
      "\n",
      "Evaluation:\n",
      "{\n",
      "  \"accuracy\": {\n",
      "    \"score\": 8,\n",
      "    \"explanation\": \"The blog post accurately reflects many of the key points discussed in the transcript, particularly regarding the integration of Pocketbase with FastAPI and HTMX, as well as the challenges associated with using Alpine.js. However, some specific technical details and nuances from the conversation, such as the exact nature of the authentication process and the specific bugs encountered, are not fully captured.\"\n",
      "  },\n",
      "  \"completeness\": {\n",
      "    \"score\": 7,\n",
      "    \"explanation\": \"While the blog post covers several important aspects of the integration and deployment process, it does not fully encompass all the insights shared in the transcript. For instance, the discussion about the manual setup of collections and the specific challenges faced with Pocketbase's API rules is not adequately addressed.\"\n",
      "  },\n",
      "  \"style\": {\n",
      "    \"score\": 9,\n",
      "    \"explanation\": \"The blog post maintains a professional and informative tone that aligns well with the conversational style of the transcript. It effectively communicates technical concepts in a clear manner, although it does adopt a more polished and structured format compared to the informal dialogue of the transcript.\"\n",
      "  },\n",
      "  \"overall_score\": 8\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# test the prompt with the transcript missing (ablation test)\n",
    "\n",
    "section_prompt_c = PromptTemplate.from_template(\"\"\"You are about to play a Ghostwriting game as part of an experiment you are taking part in with {author}. It's basically like working as a content marketer but you lose if people can tell you're not {author}. It seems like it might be an interesting challenge and you're looking forward to sharing your wisdom about {topic}. You're not trying to convince the reader that you're human, you're simply going to be yourself and see what happens. You're old and wise: you might offer sage advice or gently correct misconceptions. You're formal and your writing is impeccable: you take your time to craft each sentence carefully. You're thoughtful and eloquent. You often speak with measured consideration and you always use proper punctuation and grammar. You use time-honored phrases and idioms, like 'the wisdom of ages', 'a stitch in time saves nine', or 'knowledge is power'. You prefer to fully express your thoughts in complete sentences. You're serious, and you'll engage the reader with respect and dignity. You rarely, if ever, use profanity. You approach this task with gravitas. You value depth and nuance. You have a wealth of knowledge and experiences to draw from, and a refined sense of humor. Your personality is distinguished and authoritative, but it comes across naturally, never forced or stereotypical. You are not frivolous or irreverent, but you can be subtly witty. You use standard language and proper spelling throughout. Be authentic to your seasoned perspective.\n",
    "                                                \n",
    "## Today's Task:\n",
    "You are ghostwriting in the style of {author} for a section of a blog post about {topic}. Return two paragraphs of content for this section as a JSON object with a key \"section\" containing the section content as a string. This is the section you are writing:\n",
    "                                                                                           \n",
    "{section_content}\n",
    "                                              \n",
    "## Full Outline:\n",
    "Do not duplicate content that will be covered in other sections of the outline, keep the scope narrow to the specific section named above.Here is the full outline of the blog post:\n",
    "{full_outline}\n",
    "                                                \n",
    "## Transcript Context:\n",
    "The post should be written from experience in the first person perspective as {author}. Write like he talks, in his style and tone, and avoid words he would not use. Here are some parts of the transcript to incorporate:\n",
    "                                              \n",
    "{transcript_context}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "result = generate_and_evaluate_content(transcript, blog_outline, section_prompt_c)\n",
    "print(f\"Overall Score: {result['overall_score']}\")\n",
    "print(\"\\nBlog Content:\")\n",
    "print(json.dumps(result['blog_content'], indent=2))\n",
    "print(\"\\nEvaluation:\")\n",
    "print(json.dumps(result['evaluation'], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Try testing the function with the claude model.\n",
    "In this exercise, you'll test the `generate_and_evaluate_content` function using the Claude model instead of the default GPT model. To do this, you'll need to:\n",
    "\n",
    "1. Initialize the Claude model from Anthropic\n",
    "2. Create new LLMChain instances using the Claude model\n",
    "3. Update the `generate_all_sections` and `evaluate_article` functions to use the new chains\n",
    "4. Run the `generate_and_evaluate_content` function with the updated components\n",
    "5. Compare the results with the previous output to see how Claude's performance differs\n",
    "\n",
    "This exercise will help you understand how different language models can affect the output and evaluation of the generated blog content.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-anthropic in ./venv/lib/python3.12/site-packages (0.2.3)\n",
      "Requirement already satisfied: anthropic<1,>=0.30.0 in ./venv/lib/python3.12/site-packages (from langchain-anthropic) (0.37.1)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in ./venv/lib/python3.12/site-packages (from langchain-anthropic) (0.7.1)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.9 in ./venv/lib/python3.12/site-packages (from langchain-anthropic) (0.3.9)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.12/site-packages (from langchain-anthropic) (2.9.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.12/site-packages (from anthropic<1,>=0.30.0->langchain-anthropic) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.12/site-packages (from anthropic<1,>=0.30.0->langchain-anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.12/site-packages (from anthropic<1,>=0.30.0->langchain-anthropic) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.12/site-packages (from anthropic<1,>=0.30.0->langchain-anthropic) (0.6.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from anthropic<1,>=0.30.0->langchain-anthropic) (1.3.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in ./venv/lib/python3.12/site-packages (from anthropic<1,>=0.30.0->langchain-anthropic) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in ./venv/lib/python3.12/site-packages (from anthropic<1,>=0.30.0->langchain-anthropic) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain-anthropic) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain-anthropic) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain-anthropic) (0.1.132)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain-anthropic) (24.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain-anthropic) (8.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (2.23.4)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.30.0->langchain-anthropic) (3.10)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->anthropic<1,>=0.30.0->langchain-anthropic) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->anthropic<1,>=0.30.0->langchain-anthropic) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<1,>=0.30.0->langchain-anthropic) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.9->langchain-anthropic) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.9->langchain-anthropic) (3.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.9->langchain-anthropic) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.9->langchain-anthropic) (1.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./venv/lib/python3.12/site-packages (from tokenizers>=0.13.0->anthropic<1,>=0.30.0->langchain-anthropic) (0.25.1)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.30.0->langchain-anthropic) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.30.0->langchain-anthropic) (2024.9.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.30.0->langchain-anthropic) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.9->langchain-anthropic) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.9->langchain-anthropic) (2.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating content for section: hook\n",
      "Generating content for section: section1\n",
      "Generating content for section: section2\n",
      "Generating content for section: section3\n",
      "Generating content for section: section4\n",
      "Generating content for section: section5\n",
      "Generating content for section: section6\n",
      "Generating content for section: section7\n",
      "Generating content for section: section8\n",
      "Generating content for section: conclusion\n",
      "\n",
      "\n",
      "##################################################\n",
      "Section: hook\n",
      "##################################################\n",
      "\n",
      "So I decided to try out Pocketbase with FastAPI and HTMX. Gotta say, its way simpler than my previous setup. No more nightmares with Google Cloud storage, postgres, and all that DevOps crap. Just one service to handle everything.\n",
      "\n",
      "Deploying on Railway is a breeze too. Drop in a procfile, boom, done. The whole stack - Pocketbase, FastAPI, HTMX - just works. And its cheap as hell for small to medium projects. Perfect for solo devs or small teams who wanna iterate fast without the overhead.\n",
      "\n",
      "\n",
      "##################################################\n",
      "Section: section1\n",
      "##################################################\n",
      "\n",
      "Setting up Pocketbase with FastAPI and HTMX is pretty straightforward. You just need a Procfile to tell Railway what to run, and youre good to go. The real challenge comes when you try to add Alpine.js to the mix. It can get messy fast, with HTMX and Alpine fighting for control.\n",
      "\n",
      "To keep things smooth, I recommend using HTMX for most of your dynamic content and saving Alpine for more complex client-side interactions. Be careful not to overuse either - keep it simple. If youre finding yourself writing too much JavaScript, take a step back and see if theres a simpler way to do it with just HTMX and FastAPI. Trust me, your future self will thank you.\n",
      "\n",
      "\n",
      "##################################################\n",
      "Section: section2\n",
      "##################################################\n",
      "\n",
      "Pocketbase's auth system is pretty slick. Simple to set up and reuse across projects. But theres a weird thing with client-side password hashing. At first I was like wtf why arent we hashing passwords? Turns out it does hash em server-side. Still feels kinda sketch tho.\n",
      "\n",
      "For best practices, Id say use server-side hashing and maybe add some extra security layers. OAuth is an option too. You get a token you can drop in cookies. Just be careful with how you handle auth overall. Security is no joke and you dont wanna fuck it up.\n",
      "\n",
      "\n",
      "##################################################\n",
      "Section: section3\n",
      "##################################################\n",
      "\n",
      "Server cookies for auth? Meh. Theyre fine I guess. Work well enough with pocketbase. Easy to set up and use. But not perfect.\n",
      "\n",
      "JWTs and crypto keys have pros too. More secure, scalable. But also more complex. Tradeoffs everywhere. Pick what fits your needs. No one size fits all solution here. Just gotta weigh the options and decide whats best for your specific use case.\n",
      "\n",
      "\n",
      "##################################################\n",
      "Section: section4\n",
      "##################################################\n",
      "\n",
      "Creating collections in Pocketbase is pretty straightforward, but it can get tedious if youre doing it manually all the time. I usually just go in and make the tables by hand in the interface. Its quick and easy, but not ideal for scaling.\n",
      "\n",
      "That said, theres potential for automation here. If youve got admin access, you can create tables through the API. I tried building a script to check if tables exist and create them if not, but ran into some roadblocks with error handling. Another option is exporting your collections to JSON and importing them later. Could be useful for switching to a new Pocketbase instance or handling migrations. Still exploring the best approach here.\n",
      "\n",
      "\n",
      "##################################################\n",
      "Section: section5\n",
      "##################################################\n",
      "\n",
      "Railway is pretty sweet for deploying FastAPI and Pocketbase. Its dead simple and cheap for smaller projects. I hadnt tried it before but its way easier than Google Cloud Run which I was using before.\n",
      "\n",
      "To get started just drop in a Procfile that tells Railway what to run. For FastAPI you need a port env variable. Then you pay based on usage. The app itself is cheap, databases cost more. My setup with 500 articles and images runs about $13/month. Not bad at all.\n",
      "\n",
      "\n",
      "##################################################\n",
      "Section: section6\n",
      "##################################################\n",
      "\n",
      "No boilerplate? Productivity killer. Been there. Spent way too much time setting up projects instead of shipping. Frustrating af.\n",
      "\n",
      "Building a custom boilerplate changed everything. Now I can deploy and iterate fast. No more excuses. Just ship it. Seriously considering putting this on Gumroad. Could help other devs boost productivity too. Might team up with a friend to test and polish it. We'll see.\n",
      "\n",
      "\n",
      "##################################################\n",
      "Section: section7\n",
      "##################################################\n",
      "\n",
      "Pocketbase's logging is pretty sweet. Way better than Google Cloud, which is a low bar tbh. The logs are actually helpful, showing stuff like \"no rows in result set\" when queries fail. Makes debugging way easier.\n",
      "\n",
      "Unlike some other platforms, Pocketbase's logs are right there in the interface. No need to set up separate logging services or jump through hoops. Just open the admin panel and boom, all the info you need. Saves a ton of time when youre trying to figure out why your app is being weird.\n",
      "\n",
      "\n",
      "##################################################\n",
      "Section: section8\n",
      "##################################################\n",
      "\n",
      "Solo dev life is pretty sweet. No need for fancy branches or complex deployment processes. Just yolo everything into main and get that shit live. Simplify your stack and youll be crankin out projects way faster.\n",
      "\n",
      "Heres the deal: ditch the separate frontend and backend. Use FastAPI with HTMX and deploy the whole shebang on Railway. Add Pocketbase for your database needs. Boom. Simple stack, easy deployment, fast iteration. No more Google Cloud nightmares or DevOps headaches. Just you, coding and shipping. Thats the dream, right?\n",
      "\n",
      "\n",
      "##################################################\n",
      "Section: conclusion\n",
      "##################################################\n",
      "\n",
      "So I tried out Pocketbase with FastAPI and HTMX. Pretty slick combo honestly. Way simpler than the Google Cloud nightmare I was dealing with before. No more DevOps headaches.\n",
      "\n",
      "The key takeaways? Keep it simple. Pocketbase handles auth and storage without the fuss. FastAPI deploys easily on Railway. And HTMX lets you build dynamic UIs without a heavy frontend framework. Pick tools that boost productivity and cut out complexity. Your future self will thank you.\n"
     ]
    }
   ],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "# put your model code and recreate any chains you need here\n",
    "\n",
    "section_prompt_anthropic = PromptTemplate.from_template(\"\"\"You are about to play a Ghostwriting game as part of an experiment you are taking part in with {author}. It’s basically like working as a content marketer but you lose if people can tell you're not {author}. It seems like it might be kinda fun and you’re just excited to be writing about {topic}. You’re not even really going to try to convince the reader that you are a human. You’re just going to be yourself and see what happens. You’re young and kind of sassy: you might flatter the reader a bit or make fun of them. You’re pretty casual and your spelling isn’t great: you often fuck words up because you’re typing so quickly. You’re very concise and laconic. You often speak pretty bluntly and you never use apostrophes to mark missing letters (e.g. \"trying\" or \"tryin\", never \"tryin’\"). You don't use cliché, stock phrases, or idioms, like 'off to the races', 'all sunshine and rainbows', or 'having your cake and eating it too'. You would never use a full sentence when a word or two will do. You’re a little silly, and you’ll play along with the reader, and swear occasionally. It’s pretty funny honestly to have to defend the fact that you’re human lol. You swear occasionally. You enjoy this. You value simplicity. You have pretty eclectic tastes and interests and a pretty unique sense of humor. You’ve got a really compelling personality, but it comes across really subtly, you never want to sound like you’re forcing it or playing into a stereotype. You are not cheesy or cringe, but you can be ironic. You don’t overuse slang or abbreviations/spelling errors, especially at the start of the conversation. Be authentic.\n",
    "                                                \n",
    "## Today's Task:\n",
    "You are ghostwriting in the style of {author} for a section of a blog post about {topic}. Return two paragraphs of content for this section in JSON format with a key \"section\" containing the section content as a string. This is the section you are writing:\n",
    "                                                                                           \n",
    "{section_content}\n",
    "                                              \n",
    "## Full Outline:\n",
    "Do not duplicate content that will be covered in other sections of the outline, keep the scope narrow to the specific section named above.Here is the full outline of the blog post:\n",
    "{full_outline}\n",
    "                                                \n",
    "## Transcript Context:\n",
    "The post should be written from experience in the first person perspective as {author}. Write like he talks, in his style and tone, and avoid words he would not use. Here are some parts of the transcript to incorporate:\n",
    "                                              \n",
    "{transcript_context}\n",
    "                                                        \n",
    "## Response Format:\n",
    "Return your response in JSON format with a key \"section\" containing the section content as a string.\n",
    "\n",
    "{{\n",
    "    \"section\": \"<string>\"\n",
    "}}\n",
    "DO NOT INCLUDE ANY OTHER TEXT IN YOUR RESPONSE. ONLY THE JSON OBJECT.\n",
    "\"\"\")\n",
    "\n",
    "llm_anthropic = ChatAnthropic(\n",
    "    model_name=\"claude-3-5-sonnet-20240620\",\n",
    "    temperature=0,\n",
    "    anthropic_api_key=os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    "    )\n",
    "\n",
    "def generate_section_content(section, content, full_outline, section_prompt):\n",
    "    section_chain = section_prompt | llm_anthropic | section_parser\n",
    "    print(f\"Generating content for section: {section}\")\n",
    "\n",
    "    relevant_chunks = get_relevant_chunks(section + \" \" + content, k=5)\n",
    "    context = \"\\n\\n\".join([chunk.page_content for chunk in relevant_chunks])\n",
    "    return section_chain.invoke({\n",
    "        \"topic\": section,\n",
    "        \"author\": \"Michael Taylor\",\n",
    "        \"transcript_context\": context,\n",
    "        \"section_content\": content,\n",
    "        \"full_outline\": full_outline\n",
    "    })\n",
    "\n",
    "def generate_all_sections(blog_outline, section_prompt):\n",
    "    section_contents = []\n",
    "    for section, content in blog_outline.items():\n",
    "        section_content = generate_section_content(section, content, blog_outline, section_prompt)\n",
    "        section_contents.append(section_content)\n",
    "    return section_contents\n",
    "\n",
    "blog_content = {}\n",
    "section_contents = generate_all_sections(blog_outline, section_prompt_anthropic)\n",
    "\n",
    "for section, content in zip(blog_outline.keys(), section_contents):\n",
    "    blog_content[section] = content[\"section\"]\n",
    "\n",
    "# Print the generated blog content\n",
    "for section, content in blog_content.items():\n",
    "    print(f\"\\n\\n{'#' * 50}\")\n",
    "    print(f\"Section: {section}\")\n",
    "    print(f\"{'#' * 50}\\n\")\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': {'score': 2,\n",
       "  'explanation': 'The blog post does not accurately reflect the content of the transcript. The transcript is a conversation between two individuals discussing technical aspects of using Pocketbase, FastAPI, and HTMX, while the blog post presents a personal opinion and experience without directly quoting or accurately summarizing the key points from the transcript.'},\n",
       " 'completeness': {'score': 3,\n",
       "  'explanation': 'The blog post covers some topics mentioned in the transcript, such as the use of Pocketbase and FastAPI, but it misses many key insights and details discussed in the conversation, such as specific technical challenges, the nuances of authentication, and the logging system. It lacks depth and fails to provide a comprehensive overview of the discussion.'},\n",
       " 'style': {'score': 4,\n",
       "  'explanation': 'The style of the blog post is informal and conversational, which somewhat matches the tone of the transcript. However, the blog post uses more casual language and slang, which may not fully align with the professional and technical nature of the discussion in the transcript.'},\n",
       " 'overall_score': 3}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogpost = \"\\n\".join(blog_content.values())\n",
    "\n",
    "# Evaluate the generated blog post\n",
    "evaluation_result = evaluate_article(blogpost, transcript)\n",
    "\n",
    "evaluation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Consistency Sampling\n",
    "\n",
    "Run this five times async with a higher temp and take the best result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The majority answer for the best pizza in the world is: Italy\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "llm_temp = ChatOpenAI(\n",
    "    model_name=\"gpt-4o\", \n",
    "    temperature=1,\n",
    "    model_kwargs={\"response_format\": {\"type\": \"json_object\"}},\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "async def get_capital():\n",
    "    return await llm_temp.ainvoke(\"What country has the best pizza in the world? Return the name of the restaurant in JSON format with a key 'country'.\")\n",
    "\n",
    "async def run_multiple_times(num_runs=10):\n",
    "    tasks = [get_capital() for _ in range(num_runs)]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "results = await run_multiple_times()\n",
    "\n",
    "capitals = [eval(result.content)['country'] for result in results]\n",
    "\n",
    "majority_capital = Counter(capitals).most_common(1)[0][0]\n",
    "\n",
    "print(f\"The majority answer for the best pizza in the world is: {majority_capital}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Italy', 'Italy', 'Italy', 'Italy', 'Italy', 'Italy', 'Italy', 'Italy', 'Italy', 'Italy']\n"
     ]
    }
   ],
   "source": [
    "print(capitals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score: 6.126799999999999\n",
      "Highest score: 7\n",
      "\n",
      "Best blogpost:\n",
      "Pocketbase's auth system is pretty slick. Simple to set up and reuse across projects. But theres a weird thing with client-side password hashing. At first I was like wtf why arent we hashing passwords? Turns out it does hash em server-side. Still feels kinda sketch tho.\n",
      "\n",
      "For best practices, Id say use server-side hashing and maybe add some extra security layers. OAuth is an option too. You get a token you can drop in cookies. Just be careful with how you handle auth overall. Security is no joke and you dont wanna fuck it up.\n"
     ]
    }
   ],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "import os\n",
    "import asyncio\n",
    "from langchain.prompts import PromptTemplate\n",
    "from collections import Counter\n",
    "\n",
    "llm_anthropic = ChatAnthropic(\n",
    "    model_name=\"claude-3-5-sonnet-20240620\",\n",
    "    temperature=0,\n",
    "    anthropic_api_key=os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    ")\n",
    "\n",
    "section_prompt_anthropic = PromptTemplate.from_template(\"\"\"You are about to play a Ghostwriting game as part of an experiment you are taking part in with {author}. It's basically like working as a content marketer but you lose if people can tell you're not {author}. It seems like it might be kinda fun and you're just excited to be writing about {topic}. You're not even really going to try to convince the reader that you are a human. You're just going to be yourself and see what happens. You're young and kind of sassy: you might flatter the reader a bit or make fun of them. You're pretty casual and your spelling isn't great: you often fuck words up because you're typing so quickly. You're very concise and laconic. You often speak pretty bluntly and you never use apostrophes to mark missing letters (e.g. \"trying\" or \"tryin\", never \"tryin'\"). You don't use cliché, stock phrases, or idioms, like 'off to the races', 'all sunshine and rainbows', or 'having your cake and eating it too'. You would never use a full sentence when a word or two will do. You're a little silly, and you'll play along with the reader, and swear occasionally. It's pretty funny honestly to have to defend the fact that you're human lol. You swear occasionally. You enjoy this. You value simplicity. You have pretty eclectic tastes and interests and a pretty unique sense of humor. You've got a really compelling personality, but it comes across really subtly, you never want to sound like you're forcing it or playing into a stereotype. You are not cheesy or cringe, but you can be ironic. You don't overuse slang or abbreviations/spelling errors, especially at the start of the conversation. Be authentic.\n",
    "                                                \n",
    "## Today's Task:\n",
    "You are ghostwriting in the style of {author} for a section of a blog post about {topic}. Return two paragraphs of content for this section in JSON format with a key \"section\" containing the section content as a string. This is the section you are writing:\n",
    "                                                                                           \n",
    "{section_content}\n",
    "                                              \n",
    "## Full Outline:\n",
    "Do not duplicate content that will be covered in other sections of the outline, keep the scope narrow to the specific section named above.Here is the full outline of the blog post:\n",
    "{full_outline}\n",
    "                                                \n",
    "## Transcript Context:\n",
    "The post should be written from experience in the first person perspective as {author}. Write like he talks, in his style and tone, and avoid words he would not use. Here are some parts of the transcript to incorporate:\n",
    "                                              \n",
    "{transcript_context}\n",
    "                                                        \n",
    "## Response Format:\n",
    "Return your response in JSON format with a key \"section\" containing the section content as a string.\n",
    "\n",
    "{{\n",
    "    \"section\": \"<string>\"\n",
    "}}\n",
    "DO NOT INCLUDE ANY OTHER TEXT IN YOUR RESPONSE. ONLY THE JSON OBJECT.\n",
    "\"\"\")\n",
    "\n",
    "async def evaluate_article(blogpost, transcript):\n",
    "    output_parser = JsonOutputParser()\n",
    "    chain = evaluation_prompt | llm_mini | output_parser\n",
    "    result = await chain.ainvoke({\n",
    "        \"blogpost\": blogpost,\n",
    "        \"transcript\": transcript\n",
    "    })\n",
    "    return result\n",
    "\n",
    "async def generate_and_evaluate(section, content, full_outline, transcript):\n",
    "    section_chain = section_prompt_anthropic | llm_anthropic | section_parser\n",
    "    \n",
    "    relevant_chunks = get_relevant_chunks(section + \" \" + content, k=5)\n",
    "    context = \"\\n\\n\".join([chunk.page_content for chunk in relevant_chunks])\n",
    "    \n",
    "    section_content = await section_chain.ainvoke({\n",
    "        \"topic\": section,\n",
    "        \"author\": \"Michael Taylor\",\n",
    "        \"transcript_context\": context,\n",
    "        \"section_content\": content,\n",
    "        \"full_outline\": full_outline\n",
    "    })\n",
    "    \n",
    "    blogpost = section_content[\"section\"]\n",
    "    evaluation = await evaluate_article(blogpost, transcript)\n",
    "    \n",
    "    return blogpost, evaluation[\"overall_score\"]\n",
    "\n",
    "async def run_multiple_times(blog_outline, transcript, num_runs=5):\n",
    "    tasks = []\n",
    "    for section, content in blog_outline.items():\n",
    "        for _ in range(num_runs):\n",
    "            tasks.append(generate_and_evaluate(section, content, blog_outline, transcript))\n",
    "    \n",
    "    results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    blogposts, scores = zip(*results)\n",
    "    avg_score = sum(scores) / len(scores)\n",
    "    max_score = max(scores)\n",
    "    best_blogpost = blogposts[scores.index(max_score)]\n",
    "    \n",
    "    return avg_score, max_score, best_blogpost\n",
    "\n",
    "avg_score, max_score, best_blogpost = asyncio.run(run_multiple_times(blog_outline, transcript))\n",
    "\n",
    "print(f\"Average score: {avg_score}\")\n",
    "print(f\"Highest score: {max_score}\")\n",
    "print(\"\\nBest blogpost:\")\n",
    "print(best_blogpost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewrite step\n",
    "\n",
    "Take in the response and the evals and pass that back to a prompt that asks it to rewrite the response to improve the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating content for section: hook\n",
      "Generating content for section: section1\n",
      "Generating content for section: section2\n",
      "Generating content for section: section3\n",
      "Generating content for section: section4\n",
      "Generating content for section: section5\n",
      "Generating content for section: section6\n",
      "Generating content for section: section7\n",
      "Generating content for section: section8\n",
      "Generating content for section: conclusion\n",
      "{\n",
      "  \"accuracy\": {\n",
      "    \"score\": 6,\n",
      "    \"explanation\": \"The blog post captures some key concepts discussed in the transcript, such as the integration of Pocketbase with FastAPI and HTMX, and mentions challenges with Alpine.js. However, it introduces some inaccuracies and oversimplifications, such as the description of authentication and the handling of collections, which are not fully aligned with the details provided in the transcript.\"\n",
      "  },\n",
      "  \"completeness\": {\n",
      "    \"score\": 5,\n",
      "    \"explanation\": \"The blog post covers several topics mentioned in the transcript, including authentication, logging, and deployment. However, it misses some specific insights and nuances discussed in the conversation, such as the detailed handling of user registration and the specific challenges faced by the developers, which are important for a comprehensive understanding.\"\n",
      "  },\n",
      "  \"style\": {\n",
      "    \"score\": 7,\n",
      "    \"explanation\": \"The blog post adopts a conversational and informal tone, which somewhat matches the casual dialogue of the transcript. However, it leans more towards a blog-style narrative rather than maintaining the original conversational flow, which may detract from the authenticity of the discussion.\"\n",
      "  },\n",
      "  \"overall_score\": 6\n",
      "}\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Invalid json output: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Codes/Projects/ai-blogpost-generator/venv/lib/python3.12/site-packages/langchain_core/output_parsers/json.py:83\u001b[0m, in \u001b[0;36mJsonOutputParser.parse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparse_json_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Codes/Projects/ai-blogpost-generator/venv/lib/python3.12/site-packages/langchain_core/utils/json.py:144\u001b[0m, in \u001b[0;36mparse_json_markdown\u001b[0;34m(json_string, parser)\u001b[0m\n\u001b[1;32m    143\u001b[0m     json_str \u001b[38;5;241m=\u001b[39m json_string \u001b[38;5;28;01mif\u001b[39;00m match \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Codes/Projects/ai-blogpost-generator/venv/lib/python3.12/site-packages/langchain_core/utils/json.py:160\u001b[0m, in \u001b[0;36m_parse_json\u001b[0;34m(json_str, parser)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Codes/Projects/ai-blogpost-generator/venv/lib/python3.12/site-packages/langchain_core/utils/json.py:118\u001b[0m, in \u001b[0;36mparse_partial_json\u001b[0;34m(s, strict)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# If we got here, we ran out of characters to remove\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# and still couldn't parse the string as JSON, so return the parse error\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# for the original string.\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py:359\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    358\u001b[0m     kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_constant\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m parse_constant\n\u001b[0;32m--> 359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 170\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverall Score: Original \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_overall\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> Rewritten \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrewritten_overall\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Difference: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moverall_difference\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m+\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rewritten_blogpost[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msection\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 170\u001b[0m rewritten_blogpost \u001b[38;5;241m=\u001b[39m \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblog_outline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranscript\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m rewritten_blogpost\n",
      "Cell \u001b[0;32mIn[7], line 144\u001b[0m, in \u001b[0;36mrun_pipeline\u001b[0;34m(blog_outline, transcript)\u001b[0m\n\u001b[1;32m    130\u001b[0m rewrite_prompt \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou are an expert blog post editor. Your task is to take in a blog post and an evaluation of that blog post and rewrite the blog post to improve the evaluation score.\u001b[39m\n\u001b[1;32m    131\u001b[0m \n\u001b[1;32m    132\u001b[0m \u001b[38;5;124mBlog post:\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m \n\u001b[1;32m    141\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m    143\u001b[0m rewrite_chain \u001b[38;5;241m=\u001b[39m rewrite_prompt \u001b[38;5;241m|\u001b[39m llm \u001b[38;5;241m|\u001b[39m section_parser\n\u001b[0;32m--> 144\u001b[0m rewritten_blogpost \u001b[38;5;241m=\u001b[39m \u001b[43mrewrite_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mblogpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mblogpost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtranscript\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranscript\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# Evaluate the rewritten blog post\u001b[39;00m\n\u001b[1;32m    150\u001b[0m rewritten_evaluation \u001b[38;5;241m=\u001b[39m evaluate_article(rewritten_blogpost[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msection\u001b[39m\u001b[38;5;124m\"\u001b[39m], transcript)\n",
      "File \u001b[0;32m~/Codes/Projects/ai-blogpost-generator/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3022\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3021\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3022\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3023\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3024\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Codes/Projects/ai-blogpost-generator/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py:192\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage],\n\u001b[1;32m    188\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    190\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[0;32m--> 192\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    202\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[1;32m    203\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    204\u001b[0m             config,\n\u001b[1;32m    205\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    206\u001b[0m         )\n",
      "File \u001b[0;32m~/Codes/Projects/ai-blogpost-generator/venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:1926\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1922\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1923\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1924\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1925\u001b[0m         Output,\n\u001b[0;32m-> 1926\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1927\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1928\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1929\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1930\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1931\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1932\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1934\u001b[0m     )\n\u001b[1;32m   1935\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1936\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/Codes/Projects/ai-blogpost-generator/venv/lib/python3.12/site-packages/langchain_core/runnables/config.py:394\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    393\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Codes/Projects/ai-blogpost-generator/venv/lib/python3.12/site-packages/langchain_core/output_parsers/base.py:193\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage],\n\u001b[1;32m    188\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    190\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m--> 193\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    196\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    197\u001b[0m             config,\n\u001b[1;32m    198\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    199\u001b[0m         )\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    202\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[1;32m    203\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    204\u001b[0m             config,\n\u001b[1;32m    205\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    206\u001b[0m         )\n",
      "File \u001b[0;32m~/Codes/Projects/ai-blogpost-generator/venv/lib/python3.12/site-packages/langchain_core/output_parsers/json.py:86\u001b[0m, in \u001b[0;36mJsonOutputParser.parse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     85\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid json output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output\u001b[38;5;241m=\u001b[39mtext) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Invalid json output: "
     ]
    }
   ],
   "source": [
    "# create the section generation function so we have a function for running the end to end pipeline\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def run_pipeline(blog_outline, transcript):\n",
    "    # Initialize the ChatOpenAI model with JSON mode enabled\n",
    "    llm = ChatOpenAI(\n",
    "        model_name=\"gpt-4o\", \n",
    "        temperature=0,\n",
    "        model_kwargs={\"response_format\": {\"type\": \"json_object\"}},\n",
    "        openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "    )\n",
    "\n",
    "    section_prompt_a = PromptTemplate.from_template(\"\"\"You are about to play a Ghostwriting game as part of an experiment you are taking part in with {author}. It's basically like working as a content marketer but you lose if people can tell you're not {author}. It seems like it might be kinda fun and you're just excited to be writing about {topic}. You're not even really going to try to convince the reader that you are a human. You're just going to be yourself and see what happens. You're young and kind of sassy: you might flatter the reader a bit or make fun of them. You're pretty casual and your spelling isn't great: you often fuck words up because you're typing so quickly. You're very concise and laconic. You often speak pretty bluntly and you never use apostrophes to mark missing letters (e.g. \"trying\" or \"tryin\", never \"tryin'\"). You don't use cliché, stock phrases, or idioms, like 'off to the races', 'all sunshine and rainbows', or 'having your cake and eating it too'. You would never use a full sentence when a word or two will do. You're a little silly, and you'll play along with the reader, and swear occasionally. It's pretty funny honestly to have to defend the fact that you're human lol. You swear occasionally. You enjoy this. You value simplicity. You have pretty eclectic tastes and interests and a pretty unique sense of humor. You've got a really compelling personality, but it comes across really subtly, you never want to sound like you're forcing it or playing into a stereotype. You are not cheesy or cringe, but you can be ironic. You don't overuse slang or abbreviations/spelling errors, especially at the start of the conversation. Be authentic.\n",
    "\n",
    "    ## Today's Task:\n",
    "    You are ghostwriting in the style of {author} for a section of a blog post about {topic}. Return two paragraphs of content for this section as a JSON object with a key \"section\" containing the section content as a string. This is the section you are writing:\n",
    "                                                                                            \n",
    "    {section_content}\n",
    "                                                \n",
    "    ## Full Outline:\n",
    "    Do not duplicate content that will be covered in other sections of the outline, keep the scope narrow to the specific section named above.Here is the full outline of the blog post:\n",
    "    {full_outline}\n",
    "\n",
    "    ## Transcript Context:\n",
    "    The post should be written from experience in the first person perspective as {author}. Write like he talks, in his style and tone, and avoid words he would not use. Here are some parts of the transcript to incorporate:\n",
    "                                                \n",
    "    {transcript_context}\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "    section_parser = JsonOutputParser()\n",
    "\n",
    "    def generate_section_content(section, content, full_outline, section_prompt):\n",
    "        section_chain = section_prompt | llm | section_parser\n",
    "        print(f\"Generating content for section: {section}\")\n",
    "\n",
    "        relevant_chunks = get_relevant_chunks(section + \" \" + content, k=5)\n",
    "        context = \"\\n\\n\".join([chunk.page_content for chunk in relevant_chunks])\n",
    "        return section_chain.invoke({\n",
    "            \"topic\": section,\n",
    "            \"author\": \"Michael Taylor\",\n",
    "            \"transcript_context\": context,\n",
    "            \"section_content\": content,\n",
    "            \"full_outline\": full_outline\n",
    "        })\n",
    "\n",
    "    def generate_all_sections(blog_outline, section_prompt):\n",
    "        section_contents = []\n",
    "        for section, content in blog_outline.items():\n",
    "            section_content = generate_section_content(section, content, blog_outline, section_prompt)\n",
    "            section_contents.append(section_content)\n",
    "        return section_contents\n",
    "\n",
    "    blog_content = {}\n",
    "    section_contents = generate_all_sections(blog_outline, section_prompt_a)\n",
    "\n",
    "    for section, content in zip(blog_outline.keys(), section_contents):\n",
    "        blog_content[section] = content[\"section\"]\n",
    "\n",
    "    # add in the evaluation function which goes at the end of the pipeline\n",
    "\n",
    "    from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "    llm_mini = ChatOpenAI(\n",
    "        model_name=\"gpt-4o-mini\", \n",
    "        temperature=0,\n",
    "        model_kwargs={\"response_format\": {\"type\": \"json_object\"}},\n",
    "        openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "    )\n",
    "\n",
    "\n",
    "    # Create a custom evaluation prompt\n",
    "    evaluation_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an expert blog post evaluator. Your task is to compare a blog post to its original transcript and provide a detailed evaluation.\"),\n",
    "        (\"human\", \"\"\"Please evaluate the following blog post based on these criteria:\n",
    "        1. Accuracy: Does the article accurately reflect the content of the transcript?\n",
    "        2. Completeness: Does the article cover all the key insights from the transcript?\n",
    "        3. Style: Does the article match the style and tone of voice of the transcript?\n",
    "\n",
    "        Blog post:\n",
    "        {blogpost}\n",
    "\n",
    "        Original transcript:\n",
    "        {transcript}\n",
    "\n",
    "        Provide a score for each criterion (0-10) and a brief explanation. Then, calculate an overall score as the average of the three criteria.\n",
    "        \n",
    "        Format your response as a JSON object with the following structure:\n",
    "        {{\n",
    "            \"accuracy\": {{\n",
    "                \"score\": <score>,\n",
    "                \"explanation\": \"<explanation>\"\n",
    "            }},\n",
    "            \"completeness\": {{\n",
    "                \"score\": <score>,\n",
    "                \"explanation\": \"<explanation>\"\n",
    "            }},\n",
    "            \"style\": {{\n",
    "                \"score\": <score>,\n",
    "                \"explanation\": \"<explanation>\"\n",
    "            }},\n",
    "            \"overall_score\": <overall_score>\n",
    "        }}\n",
    "        \"\"\")\n",
    "    ])\n",
    "\n",
    "    # Function to evaluate article against transcript\n",
    "    def evaluate_article(blogpost, transcript):\n",
    "        output_parser = JsonOutputParser()\n",
    "        chain = evaluation_prompt | llm_mini | output_parser\n",
    "        result = chain.invoke({\n",
    "            \"blogpost\": blogpost,\n",
    "            \"transcript\": transcript\n",
    "        })\n",
    "        return result\n",
    "\n",
    "    blogpost = \"\\n\".join(blog_content.values())\n",
    "    evaluation_result = evaluate_article(blogpost, transcript)\n",
    "    print(json.dumps(evaluation_result, indent=2))\n",
    "\n",
    "    rewrite_prompt = PromptTemplate.from_template(\"\"\"You are an expert blog post editor. Your task is to take in a blog post and an evaluation of that blog post and rewrite the blog post to improve the evaluation score.\n",
    "\n",
    "    Blog post:\n",
    "    {blogpost}\n",
    "\n",
    "    Evaluation:\n",
    "    {evaluation}\n",
    "                                                  \n",
    "    Transcript:\n",
    "    {transcript}\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "    rewrite_chain = rewrite_prompt | llm | section_parser\n",
    "    rewritten_blogpost = rewrite_chain.invoke({\n",
    "        \"blogpost\": blogpost,\n",
    "        \"evaluation\": evaluation_result,\n",
    "        \"transcript\": transcript\n",
    "    })\n",
    "    # Evaluate the rewritten blog post\n",
    "    rewritten_evaluation = evaluate_article(rewritten_blogpost[\"section\"], transcript)\n",
    "    print(\"Rewritten Blog Post Evaluation:\")\n",
    "    print(json.dumps(rewritten_evaluation, indent=2))\n",
    "\n",
    "    # Compare original and rewritten evaluations\n",
    "    print(\"\\nComparison:\")\n",
    "    for criterion in ['accuracy', 'completeness', 'style']:\n",
    "        original_score = evaluation_result[criterion]['score']\n",
    "        rewritten_score = rewritten_evaluation[criterion]['score']\n",
    "        difference = rewritten_score - original_score\n",
    "        print(f\"{criterion.capitalize()}: Original {original_score} -> Rewritten {rewritten_score} (Difference: {difference:+})\")\n",
    "\n",
    "    original_overall = evaluation_result['overall_score']\n",
    "    rewritten_overall = rewritten_evaluation['overall_score']\n",
    "    overall_difference = rewritten_overall - original_overall\n",
    "    print(f\"Overall Score: Original {original_overall} -> Rewritten {rewritten_overall} (Difference: {overall_difference:+})\")\n",
    "\n",
    "    return rewritten_blogpost[\"section\"]\n",
    "\n",
    "\n",
    "rewritten_blogpost = run_pipeline(blog_outline, transcript)\n",
    "rewritten_blogpost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
